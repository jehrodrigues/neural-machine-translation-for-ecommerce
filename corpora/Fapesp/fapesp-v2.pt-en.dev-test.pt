Tecnologia > Física
Laboratório finaliza projeto de um novo anel para produção de luz síncrotron
Marcos de Oliveira
O maior instrumento de pesquisa científica e tecnológica do país deverá ganhar uma versão maior e mais potente até 2015.
Essa radiação é gerada por elétrons que são produzidos num acelerador e inseridos dentro de um anel metálico com 93 metros (m) de circunferência – o novo terá 460 m de circunferência – em meio a um ambiente de ultra-alto vácuo.
A nova fonte já ganhou o nome de Sirius – escolhido entre sugestões de funcionários – em referência à estrela mais brilhante no céu noturno.
A construção desse instrumento é importante porque o atual está se tornando obsoleto.
O Síncrotron brasileiro completa 13 anos de serviço em 2010, e as exigências científicas e tecnológicas indicam a necessidade de um equipamento mais atualizado.
“A evolução é necessária porque a ciência, no fundo, é competição.
As perguntas importantes e relevantes, nessas áreas atendidas pelo Síncrotron, são sempre novas, porque parte das antigas já foi respondida.
Então, as novas exigem equipamentos mais sofisticados”, diz o físico Antônio José Roque da Silva, diretor do LNLS desde julho de 2009 e professor do Instituto de Física da Universidade de São Paulo (USP).
Uma das vantagens de um laboratório como o Síncrotron é o caráter interdisciplinar com pesquisadores em biologia, ciências dos materiais, tecnologia, energia e paleontologia.
“Com o LNLS, o país pode competir em várias áreas e utilizar o mesmo laboratório, simultaneamente, ao longo do ano inteiro para fazer seus experimentos.”
Hoje existem cerca de 50 fontes de luz síncrotron no mundo, sendo 16 de terceira geração que começaram a funcionar a partir de 1994.
Elas são caracterizadas por possuírem uma radiação mais brilhante, com maior quantidade de luz gerada e baixa emitância, unidade de grandeza usada para determinar o tamanho e a divergência (espalhamento) do foco da fonte de luz.
A Sirius está sendo projetada para ter 1,7 nanômetro-radiano (nm.rad), enquanto a atual possui 100 nm.rad.
Isso significa maior brilho num feixe de radiação menor e com ângulo de abertura também menor.
Ela deverá ser uma das fontes mais brilhantes do mundo.
O Synchrotron Soleil, por exemplo, construído na cidade de Saint-Aubin, na França, inaugurado em 2006, tem emitância de 3,7 nm.rad e o Diamond, localizado em Oxfordshire, na Inglaterra, que começou a funcionar em 2007, possui 2,7 nm.rad.
“Das 50 fontes de radiação síncrotron no mundo apenas 30 são abertas a pesquisadores de fora da instituição a que pertence o laboratório.
São 11 na Europa, 7 nos Estados Unidos, 10 na Ásia, 1 na Austrália e 1 na América do Sul, que é o LNLS.
Se a segunda fonte não for construída, o Brasil e a América do Sul vão desaparecer do mapa da radiação síncrotron do mundo’’, diz o físico francês Yves Petroff, diretor científico do LNLS desde dezembro de 2009 e responsável pelos objetivos científicos do projeto da nova fonte.
Desses estudos resultaram cerca de 250 artigos publicados em revistas científicas.
“Países menores como Espanha, Coreia do Sul e Taiwan estão construindo fontes de terceira geração”, diz Petroff.
Com 73 anos, ele tem um longo percurso em laboratórios síncrotrons do mundo.
Foi diretor-geral do European Synchrotron Radiation Facility (ESRF), em Grenoble, na França, de 1993 a 2001, além de ter trabalhado em laboratórios semelhantes nos Estados Unidos.
Também assumiu as diretorias científicas do Laboratório para Utilização da Radiação Eletromagnética (Lure, na sigla em francês) e do Centro Nacional de Pesquisa Científica (CNRS, na sigla em francês).
Participa de vários comitês científicos de síncrotrons, inclusive o do LNLS desde a fase de implantação em 1988.
“É interessante notar que o número de usuários do Departamento de Energia em quatro síncrotrons nos Estados Unidos cresceu 40%, de 6 mil para 8.400, entre 2000 e 2008, enquanto os usuários do francês ESRF cresceram 36% entre 2003 e 2009”, diz.
“Grande parte desse crescimento se deve ao uso dessa radiação para estudos de estruturas biológicas.
Todas as companhias farmacêuticas, por exemplo, utilizam as linhas de luz para esse fim.”
Ele lembra também que recentemente a exploração de específicas propriedades do raio X produzido pelas máquinas síncrotron estão permitindo obter imagens tridimensionais de qualquer objeto com resolução abaixo do micrômetro (um milímetro dividido por mil) como em estudos de paleontologia, arqueologia e meio ambiente.
“Convidei o Yves Petroff para reestruturarmos a divisão científica do LNLS e para ele ajudar nos objetivos da ciência que se quer fazer com a nova fonte e as novas linhas de luz que estão ficando cada vez mais sofisticadas”, diz Roque.
Ímãs permanentes – Além de atingir as especificações exigidas de uma fonte de luz síncrotron de terceira geração, o projeto contempla uma profunda redução no consumo de eletricidade.
Para isso novas soluções já estão sendo testadas dentro do LNLS utilizando tecnologias inovadoras.
A primeira é a adoção de ímãs permanentes, uma novidade mundial para esse tipo de laboratório.
Esses dipolos hoje funcionam por meio de eletroímãs, que são formados por metais envoltos por fios que quando recebem corrente elétrica se transformam em ímãs.
Eles exigem uma série de outros instrumentos acoplados como sistema de refrigeração e bobinas que gastam muita eletricidade.
“Os ímãs permanentes são semelhantes aos ímãs de geladeira”, compara Rodrigues.
Eles não necessitam de energia elétrica para funcionar e são vendidos comercialmente no mundo inteiro.
São feitos de ferrite, um material barato, e de ligas com neodímio, ferro e boro.
Até agora existe apenas uma máquina no mundo, um acumulador de antiprótons, no Fermilab, nos Estados Unidos, que funciona com ímãs permanentes.
“Ninguém ainda teve coragem de fazer isso em síncrotrons, embora o conhecimento desses materiais tenha avançado bastante”, diz Rodrigues.
A redução do consumo de energia pesa muito nessa decisão.
Com os ímãs permanentes espera-se uma economia de 6,5 gigawatts-hora (GWh) por ano – cerca de R$ 4,5 milhões por ano.
Outra inovação desenvolvida no Síncrotron, em colaboração com o laboratório francês Soleil, vai servir tanto à nova quanto à atual fonte.
É um sistema de radiofrequência (RF) radicalmente diferente, que irá economizar mais de R$ 1 milhão em energia elétrica por ano.
A conta de luz atual do laboratório gira em torno de R$ 3,5 milhões anuais.
O sistema RF é o responsável por repor a energia perdida pelos elétrons na forma de luz síncrotron.
Embora contando com o que há de mais avançado em tecnologias, a quase totalidade desses laboratórios no mundo funciona com uma válvula eletrônica de quase um metro de comprimento que custa US$ 150 mil a unidade.
As válvulas eram muito usadas em aparelhos eletrônicos antes do aparecimento comercial dos transistores de potência.
No caso dos síncrotrons, elas são fabricadas especialmente na Inglaterra para suprir a alta energia usada para amplificar a frequência de 476 mega-hertz (MHz).
Essa onda eletromagnética, em vez de se expandir no espaço, como numa estação de rádio, por exemplo, é aprisionada dentro de câmaras, chamadas de cavidades ressonantes, ao longo do anel.
A fonte atual utiliza dois desses geradores de RF de 30 quilowatts (kW) cada um.
“Até agora a única maneira de juntar altas potências e altas frequências era essa válvula”, diz o técnico eletrônico Claudio Pardine, coordenador do laboratório de radiofrequência do LNLS.
Pardine, em colaboração com os franceses do Soleil, desenvolveu o novo sistema chamado de amplificador de estado sólido, formado por centenas de pequenas caixas eletrônicas com potência de 250 watts.
“Já em 2001, o LNLS foi o primeiro laboratório do mundo a substituir a válvula pelo amplificador de estado sólido em um sistema de um kW para um injetor de luz síncrotron”, diz Pardine.
As vantagens são inúmeras, mas a maior é mesmo a economia de energia elétrica.
“Para suprir os 30 kW, o sistema tradicional com válvula precisa de uma potência de 170 kW; o novo, em estado sólido, necessita de 60 kW.”
Atualmente, o sistema de RF utiliza quase 1,8 gigawatt--hora (GWh) por ano que representa um gasto com eletricidade referente ao equipamento de RF de R$ 1,3 milhão no ano.
Com a implantação do novo sistema, a economia vai ser de 50%, sem contar a economia em ter que trocar a válvula a cada cinco anos.
“Não ficamos reféns do fabricante.
A manutenção torna-se mais fácil e barata.”
O francês Soleil foi o primeiro a instalar um amplificador de estado sólido de várias dezenas de quilowatts.
“Nós construímos alguns componentes desses amplificadores no LNLS para eles em 2005”, lembra Pardine.
“Vendemos a preço de custo as peças para fazer protótipos que eles e nós desenvolvemos em parceria.”
Pardine tem como mestre o pesquisador chinês Ti Ruan, que hoje trabalha no Soleil e era professor da Universidade de Paris.
Ruan convenceu os diretores do laboratório francês, durante a construção, a utilizarem o amplificador de estado sólido.
Outro grande laboratório, o Diamond, na Inglaterra, inaugurado em 2007, preferiu a válvula.
Pardine ressalta que a ideia de usar os amplificadores de estado sólido é antiga, mas só agora é possível pela evolução dos materiais e equipamentos eletrônicos.
Para desenvolver e construir as novas torres de RF, ele conseguiu um financiamento da Financiadora de Estudos e Projetos (Finep), num programa para equipamentos de energia elétrica, no valor de R$ 1 milhão.
Chão firme - Para funcionar de forma exemplar, a Sirius precisará de uma superestabilidade do grande anel de armazenamento para que os elétrons não desviem mais que um milésimo de milímetro (micrômetro) da órbita projetada.
A mesma superestabilidade vale também para as linhas de luz.
“Há pequenas variações do solo imperceptíveis em condições normais, mas quando se trabalha em medidas de micrômetros elas se tornam muito importantes”, diz Ricardo Rodrigues.
O projeto prevê um superpiso enrijecido que terá 200 metros de diâmetro e 1 metro de espessura, sem emenda.
“Ninguém fez esse piso no Brasil.
São 20 mil metros cúbicos de concreto que precisam ser produzidos em uma semana, durante 24 horas por dia.
As camadas vão sendo colocadas uma sobre a outra e a cura (secagem) do material não pode ser rápida.”
Uma logística especial deverá ser montada, com a instalação de uma fábrica de concreto e outra de gelo ao lado da construção da nova fonte.
O orçamento inicial previsto para a Sirius é de aproximadamente R$ 400 milhões distribuídos ao longo de seis anos.
Dinheiro que deverá ser bancado de forma independente pelo Ministério da Ciência e Tecnologia (MCT) ou em parceria com outras instituições federais.
Todos os três estão sob a coordenação do Centro Nacional de Pesquisas em Energia e Materiais (CNPEM), que em junho passa a ser comandado pelo professor Walter Colli, ex-professor do Instituto de Química da Universidade de São Paulo (USP).
À frente do projeto, o LNLS tem uma equipe experiente que já sabe como se constrói um síncrotron.
Ricardo Rodrigues foi um dos três primeiros pesquisadores contratados em agosto de 1986 pelo Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), na época o gestor do LNLS, para construir o laboratório.
“Eram o Cylon Gonçalves da Silva, como diretor, o Aldo Craievich, para cuidar do uso do laboratório pelos pesquisadores e eu para cuidar do projeto e construção que levou 10 anos”, lembra Rodrigues.
Adquirir a experiência e o conhecimento foi demorado.
Acho que usamos o melhor método para aprender alguma coisa.
O pessoal contratado, um engenheiro ou um físico que acabava de sair da universidade, recebia o seguinte recado: ‘Você vai ter que fazer isso.
Vamos ajudar no que puder, vamos trabalhar juntos.’
Ninguém foi fazer um doutorado, um curso especial.
Nós mandávamos fazer viagens, as pessoas iam visitar outros laboratórios e perguntavam: ‘Como é que você faz?’”, diz Rodrigues.
A física Liu Lin foi uma dessas profissionais que fizeram parte da equipe inicial.
“Em 1985, quando eu fazia mestrado no Instituto de Física da USP, em São Carlos, trabalhei no projeto da rede magnética do anel onde fiz simulações da dinâmica do feixe de elétrons.
Depois estive na equipe que ficou por três meses no Stanford Linear Accelerator Center (Slac), da Universidade de Stanford, na Califórnia, nos Estados Unidos”, diz Liu.
“Aprendemos muito porque lá eles fazem os instrumentos e nós tivemos a oportunidade de projetar uma máquina fictícia que nos fez conhecer a física dos aceleradores”, diz Rodrigues.
Esse mesmo propósito de construir instrumentos e sistemas que esteve na construção do primeiro anel permanece para o próximo.
“Nós projetamos e compramos uma série de coisas, mas financeiramente apenas 16% da primeira máquina foi importado.”
Atual líder do Grupo de Física de Aceleradores do LNLS, Liu estuda a dinâmica dos elétrons sob a ação do campo eletromagnético.
“Projetamos esses campos para assegurar que um feixe intenso de elétrons com alta energia possa ficar armazenado de maneira estável produzindo luz síncrotron durante várias horas.
Para conseguirmos isso precisamos especificar, entre outros, uma rede magnética que vai definir todas as propriedades do feixe de luz síncrotron produzido”, diz Liu.
Para Rodrigues, o projeto está quase finalizado e a perspectiva é que a construção demore metade do tempo da primeira máquina.
“Agora não é urgente formar pessoal, o núcleo de pessoas que coordenam o projeto ainda está jovem.”
Tecnologia > Óptica
Imagem tridimensional
Protótipo de TV 3D dispensa o uso de óculos especiais
Yuri Vasconcelos
A tecnologia televisiva em três dimensões (3D) é um dos grandes atrativos da Copa do Mundo da África do Sul para os torcedores que não tiverem a oportunidade de viajar e assistir aos jogos nos estádios sul-africanos.
Vinte e cinco partidas do torneio – inclusive as três do Brasil na primeira fase da competição – estão sendo transmitidas em 3D, a mesma que conquistou milhões de espectadores mundo afora com a exibição do filme Avatar nos cinemas.
A exemplo da superprodução dirigida por James Cameron, o telespectador precisa usar óculos especiais para ver as partidas em imagens tridimensionais, que dão a sensação de profundidade e relevo.
No futuro, entretanto, especialistas estimam que a tecnologia 3D não será mais refém desse incômodo artefato no rosto, que gera desconforto e causa cansaço visual e dores de cabeça em algumas pessoas – sem falar no problema de higiene em compartilhar óculos no cinema.
Em vários países estão sendo desenvolvidas pesquisas visando à criação de uma TV tridimensional que dispense o uso de óculos especiais.
No Brasil, essa tecnologia ganha formato nos estudos de pesquisadores da Universidade Estadual de Campinas (Unicamp).
Liderados pelo professor Jose Joaquin Lunazzi, eles desenvolveram vários protótipos de um televisor tridimensional que exibe imagens holográficas.
“Nossa tecnologia, batizada de Holo TV, pretende liberar o uso de óculos e oferecer total conforto de visão.
Ela não tem semelhança com sistema nenhum existente no mundo, mesmo em se tratando de protótipos”, explica Lunazzi.
“Trata-se de imagens projetadas sobre telas quase transparentes, em que a falta de visão do suporte gera uma figura fantasma que as torna semelhantes às holográficas.
A cena filmada pode ser vista sem óculos com a suavidade e a naturalidade de um holograma”, diz.
Um dos pioneiros no país no estudo da holografia, Lunazzi iniciou suas pesquisas para a criação de uma TV tridimensional em 1984.
Dez anos depois conseguiu apoio da Fapesp e adquiriu uma filmadora, um projetor, um filme holográfico, um aparelho de laser e uma objetiva fotográfica.
Com esses instrumentos constituiu um sistema de geração e reprodução de imagens holográficas.
Em 1988 apresentou o primeiro protótipo de seu televisor 3D holográfico.
Fora da tela - Assim como os aparelhos dotados da tecnologia 3D tradicional, que exigem o uso de óculos especiais, as TVs tridimensionais holográficas também projetam imagens para fora da tela, mas ainda precisam de certos ajustes para serem colocadas no mercado.
Centros de pesquisa, como o Instituto de Tecnologia de Massachusetts (MIT), empresas de alta tecnologia, como a húngara Holografika, e grandes fabricantes de aparelhos eletrônicos trabalham para construir modelos comerciais.
No ano passado, a fabricante holandesa Philips realizou testes de um televisor 3D que dispensava o uso de óculos, mas exigia que o telespectador se sentasse numa posição fixa diante do aparelho, sob risco de ver as imagens embaralhadas.
Por conta dessa limitação, o desenvolvimento foi interrompido.
O aparelho utilizava uma tecnologia conhecida como autoestereoscopia, em que as lentes da tela do aparelho criam múltiplas regiões alternadamente em frente à própria tela.
Essa mesma tecnologia foi usada pela fabricante coreana Samsung em um protótipo mostrado ao público em janeiro deste ano durante a Consumer Electronics Show (CES) 2010, maior feira de eletrônicos do mundo, realizada em Las Vegas, nos Estados Unidos.
Mais recentemente, em abril último, a empresa japonesa VMJ apresentou, numa feira de tecnologia em Tóquio, uma TV de 65 polegadas que exibe produções 3D sem a exigência de óculos.
A tecnologia fez sucesso, mas precisa vencer alguns obstáculos para se tornar comercial, como a redução de custo de produção e a dispensa da exigência de o telespectador permanecer em determinadas posições em relação ao visor para ver a imagem corretamente – mesma barreira enfrentada pelos modelos da Philips.
A tecnologia criada na Unicamp, de acordo com Lunazzi, não padece dessa dificuldade.
“A pessoa pode mudar de posição quando quiser sem perder a ilusão da tridimensionalidade”, garante.
Isso se deve à descoberta de um princípio óptico chamado de codificação-decodificação de profundidade por difração da luz.
“Esse princípio foi desenvolvido por mim ao voltar de uma exposição de holografia na Alemanha, em 1984, e foi divulgado em um artigo na revista Optical Engineering, em 1990.
Desde então não foi aplicado por ninguém.
Temos avançado em nossas pesquisas, mas até agora só conseguimos criar imagens tridimensionais monocromáticas, sem cor nem brilho.”
No começo do ano passado, Lunazzi escreveu, em conjunto com três colegas de seu grupo, um novo artigo na revista Optics Letters, descrevendo o sistema criado por eles, que tem uma tela de 30 por 60 centímetros.
Um detalhe importante da tecnologia é que a tela, transparente e feita de filme fotográfico com sais de prata de alta resolução, é iluminada obliquamente de lado – diferentemente das telas convencionais que são iluminadas por trás ou pela frente.
Esse aspecto é fundamental, segundo o pesquisador, para que o processo aconteça e o telespectador tenha liberdade de movimento sem perda da ilusão tridimensional das imagens.
Lunazzi já apresentou sua tecnologia em congressos realizados no Japão, China, Estados Unidos, Coreia do Sul e países da Europa.
“A Holo TV tem caráter experimental, de protótipo.
É útil para incentivar a pesquisa no mundo e mostrar que podemos ter pesquisa tecnológica de ponta no Brasil.”
No estágio atual, ela poderia ser usada em estandes promocionais de empresas em feiras.
Em 2008, pesquisadores da Samsung visitaram o laboratório de Lunazzi, no Instituto de Física da Unicamp, para conhecer uma nova técnica de holografia por dupla difração de luz branca sem a intermediação da lente existente na Holo TV.
Mas não foi fechado nenhum acordo.
O pesquisador acredita que a viabilidade comercial de sua TV tridimensional passe por uma parceria com um grande fabricante mundial de eletroeletrônicos que se interesse em investir nessa pesquisa.
> Artigo científico
Holo-television system with a single plane.
Optics Letters.
v.
34, p.
533-35 (2009).
O PROJETO
Modalidade
Jose Joaquin Lunazzi – Unicamp
Investimento
Tecnologia > Computação
Convergência virtual
Microsoft Research usa lógica de filtros anti-spam para encontrar pontos vulneráveis do vírus HIV
Dinorah Ereno
A mesma estratégia utilizada para criar os filtros que barram os spams, as mensagens eletrônicas não solicitadas que invadem as nossas caixas de e-mails, está sendo usada pela equipe do pesquisador David Heckerman, diretor sênior do Grupo de Pesquisa em eScience da Microsoft Research, para desenvolver uma vacina contra o HIV, o vírus da aids.
“Percebemos que para ter sucesso em uma vacina seria necessário atacar pontos específicos do vírus, da mesma forma que os filtros anti-spam fazem quando selecionam os e-mails”, disse Heckerman, durante conferência no Faculty Summit 2010 da América Latina.
O evento foi realizado em parceria entre a Microsoft Research e a FAPESP de 12 a 14 de maio no Guarujá, no litoral paulista, e teve como tema “Computação: fazendo a diferença”.
Mais de 200 especialistas em computação de 13 países estiveram presentes na sexta edição do Faculty Summit, acompanhando as apresentações de projetos inovadores em vários campos do conhecimento.
Médico de formação com doutorado em ciência da computação, Heckerman foi um dos responsáveis pela criação do primeiro programa de detecção e filtragem de spam em 1997.
“Assim como os spammers mudaram os seus e-mails para passar pelos nossos filtros, o HIV também passa por mutações para enganar o sistema imunológico e conseguir se reproduzir livremente”, comparou.
A grande dificuldade em desenvolver uma vacina para o vírus que causa a aids é que ele muda constantemente.
“Mas acreditamos que existam algumas regiões do genoma do HIV que seriam vulneráveis à mutação”, disse o pesquisador.
Encontrar essas regiões é uma tarefa bastante complexa, porque é preciso mapear todas as possíveis mutações do vírus e das configurações da proteína HLA (antígenos de leucócitos humanos, na sigla em inglês), que é a ferramenta usada pelo sistema imunológico para impedir a reprodução do HIV.
A HLA invade o vírus e retira o epitopo, um fragmento de proteína responsável pela informação genética do HIV.
“Estamos procurando essas regiões chamadas de epitopos vulneráveis”, disse Heckerman.
“O nosso objetivo é desenvolver uma vacina que ensine o sistema imune a reconhecer apenas os pontos vulneráveis ao longo da sequência do material genético do HIV.”
Para isso, mais de uma centena de pesquisadores no mundo todo está usando uma ferramenta chamada PhyloD, desenvolvida pelo grupo de Heckerman, para avaliar como o HIV se comporta a partir do momento em que infecta uma pessoa.
Computadores cruzam os dados do sistema imunológico das pessoas e da evolução e mutação do HIV em seus corpos, indicando assim quais características genéticas ajudam a combater o vírus.
As estatísticas geradas até agora resultaram na criação de uma vacina experimental, que deverá começar a ser testada dentro de seis meses.
“Se tudo der certo, talvez tenhamos um resultado efetivo em dois anos.”
Aliado móvel - Enquanto não se consegue uma vacina eficaz contra a aids, os pacientes têm que seguir um rígido esquema de horários para tomar os medicamentos antirretrovirais.
Mas essa tarefa nem sempre é seguida à risca.
Uma experiência feita no Peru com pessoas infectadas com o HIV, coordenada pelo pesquisador Walter Curioso, da Universidad Peruana Cayetano Heredia, que também é professor assistente afiliado à Universidade de Washington, Estados Unidos, mostrou que o celular pode ajudar os pacientes a seguir corretamente o tratamento prescrito.
“Mesmo quando os remédios são fornecidos gratuitamente, 88% não se medicam por diversas razões”, disse.
O principal motivo alegado para não seguir o tratamento é o esquecimento, já que são vários tipos de remédio tomados ao longo do dia.
Morar distante dos centros de saúde e preocupação com a discriminação ao ser identificado como portador do vírus foram outras razões citadas.
Como o celular já se tornou um item indispensável para a maioria das pessoas, o grupo de pesquisa resolveu recorrer a mensagens SMS (sigla em inglês para serviço de mensagens curtas) para conseguir a adesão ao tratamento.
Dessa forma, eles deram a um instrumento popular um uso inovador.
“Os pacientes estavam interessados não só em receber um lembrete para tomar os medicamentos, mas também em algo motivador, como ‘agora é a hora da sua vida’”, relatou o pesquisador.
A frase funciona como um código, porque preserva a privacidade do paciente.
A pesquisa de caráter qualitativo foi feita com 20 homens e seis mulheres portadores de HIV, que avaliaram de maneira positiva o sistema de mensagens via SMS.
A experiência resultou no Projeto Cell Pos, desenvolvido pela universidade peruana em colaboração com a norte-americana e apoio da Microsoft Research, que envia mensagens para os participantes inscritos.
Programas semelhantes de auxílio à saúde têm sido empregados com sucesso em países em desenvolvimento como Botsuana, África do Sul e Filipinas.
“Nas Filipinas houve um aumento de 90% de adesão ao tratamento entre pessoas com tuberculose que receberam mensagens via celular”, disse.
Sistema preventivo - No Brasil, o grupo de pesquisa coordenado pelo professor Jacques Wainer, do Instituto de Computação da Universidade Estadual de Campinas (Unicamp), trabalha no desenvolvimento de um sistema capaz de detectar alterações na imagem de fundo de olho indicativas de algum grau de retinopatia diabética, doença que pode levar à cegueira.
O diabetes afeta a passagem de sangue na retina, devido ao enfraquecimento das veias e artérias locais, provocando hemorragias e cicatrizes, que interferem na visão.
A proposta do projeto, aprovado em 2008 na segunda chamada lançada pelo Instituto Microsoft Research-FAPESP de Pesquisas em Tecnologia da Informação, é facilitar a triagem dos pacientes que devem ser submetidos a exames especializados.
Desde 2007, quando o instituto foi criado, as duas instituições já investiram mais de R$ 3,5 milhões em 11 projetos brasileiros nas áreas de saúde, educação, inclusão digital, agricultura, governo eletrônico, biodiversidade, bioenergia e mudanças climáticas globais.
A pesquisa do grupo de Wainer está usando uma técnica não comum em processamento de imagens médicas, que se baseia em descobrir pontos onde há mudanças significativas de cor e textura.
``Os pontos onde houve mudança de cor ou de textura equivalem a uma palavra'', disse Wainer.
A ideia é que cada tipo de ponto represente ``palavras'' nessas imagens.
Cada imagem tem, em média, 300 desses pontos.
A partir dessas palavras visuais a pesquisa se desenvolve em duas linhas distintas.
Uma delas trabalha com cada tipo de anomalia da retina, a partir de 8 mil imagens previamente classificadas.
``As imagens mais frequentes do nosso conjunto de dados relacionam-se ao exsudato, um líquido com alto teor de proteínas produzido como reação a danos nos tecidos e vasos sanguíneos'', disse Wainer.
Usando esse método, descobre-se que palavras visuais são mais indicativas da presença de exsudatos na imagem.
``É uma técnica bastante precisa, mas demorada, pois é preciso adaptá-la para cada um dos vários tipos de anomalia possíveis nas retinopatias diabéticas.''
O sistema tem 90% de sensibilidade, ou seja, 10% de falsos negativos para a detecção de exsudatos.
A outra vertente do projeto de pesquisa tenta descobrir quais são as palavras visuais que distinguem quais são as imagens normais e anormais, sem precisar buscar anomalias particulares como exsudatos ou microaneurismas.
A previsão é que, no primeiro semestre de 2011, o sistema esteja totalmente pronto.
``Um dos principais objetivos do projeto, do ponto de vista social, é criar uma infraestrutura de comunicação de dados, de baixo custo, para permitir a ligação entre as fazendas e a cooperativa e, assim, o acesso das fazendas à internet'', disse Claudia.
O projeto envolve pesquisadores em computação e em ciências agrárias.
Os novos softwares que estão sendo criados vão cruzar e tratar dados fornecidos tanto por sensores instalados no campo, que medirão variáveis como temperatura, umidade e luminosidade, quanto por satélites, que darão informações como biomassa ou as condições da cobertura vegetal.
Com as ferramentas computacionais desenvolvidas, especialistas poderão fazer um melhor planejamento das atividades da cadeia produtiva, otimizando recursos e, portanto, auxiliando os pequenos agricultores em suas tarefas.
Os produtores também poderão participar do processo decisório, a partir da rede de comunicação de dados, fornecendo informações para os especialistas -- no caso, a cooperativa --, recebendo de volta e fornecendo feedback sobre os dados.
``Isso é a estrada de mão dupla do título do projeto, em que o agricultor não apenas recebe informação, mas participa ativamente de todo o processo de geração de conhecimento para melhorar o seu trabalho'', disse Claudia.
O eFarms já está com vários módulos em funcionamento e outros serão integrados ainda este ano.
``O projeto permitiu o treinamento de pesquisadores em um trabalho multidisciplinar, formando vários mestrandos e alunos de doutorado.''
Dois principais desafios do projeto, que terminou no dia 31 de maio, mas terá continuidade com financiamento da Cooxupé, ainda precisam ser vencidos.
O primeiro deles é reproduzir em algumas fazendas da cooperativa a infraestrutura de redes de comunicação de dados que foram testadas no ambiente controlado da Unicamp.
``Isso envolve um trabalho de levantamento de terreno, especificação de infraestrutura, definição de onde colocar antenas e pontos de coleta.''
O segundo desafio é continuar a coleta e processamento de dados de sensores, mostrando os resultados coletados na rede de diversas formas.
``Os dados coletados já podem ser vistos em tempo real, na web, sob forma de gráfico.
Agora queremos continuar a pesquisa, incluindo o uso de mapas'', disse Claudia.
Atualmente o trabalho envolve testar a rede em quatro propriedades rurais de difícil acesso.
A partir dos resultados dessa etapa, a cooperativa poderá estimar os custos de implantação em escala, atingindo potencialmente 14 mil propriedades.
Os projetos
1.
2.
Modalidade
1.
Jacques Wainer - Unicamp
2.
Claudia Maria Bauzer Medeiros - Unicamp
Investimento
1.
R$ 290.966,00 (FAPESP)
Tecnologia > Engenharia da Computação
Código vegetal
Um sistema para identificação automática de frutas e legumes
Evanildo da Silveira
O tempo gasto pelo caixa de um supermercado de Campinas para localizar numa lista impressa os códigos referentes a frutas e legumes chamou a atenção do professor de ciên­cia da computação Anderson de Rezende Rocha, da Universidade Estadual de Campinas (Unicamp).
Enquanto os produtos com códigos de barra em suas embalagens eram registrados rapidamente, a identificação daqueles vegetais atravancava o andamento da fila.
Surgiu ali a ideia de desenvolver um sistema capaz de distinguir esse tipo de produto vendido a granel, difícil de ser identificado pelo leitor eletrônico do caixa porque não possui um código.
A solução encontrada por Rocha em conjunto com os pesquisadores Daniel Hauagge, Jacques Wainer e Siome Goldenstein, também do Instituto de Computação da Unicamp, foi desenvolver um sistema, com uma câmera instalada sobre a balança do caixa, para analisar imagens do produto a ser classificado.
O software desenvolvido por eles é capaz de diferenciar os vários vegetais a partir da combinação de características de cada um.
Rocha explica que a câmera captura apenas a imagem do produto.
As informações são extraídas pelo sistema utilizando-se de algoritmos (cálculos matemáticos) de processamento de imagens e reconhecimento de padrões.
Apesar de parecer complicado, o funcionamento da invenção desenvolvida durante o doutorado de Rocha – orientado pelo professor Siome Goldenstein e com bolsa da FAPESP – é simples.
Ele possui dois estágios: treinamento e teste.
Durante o treinamento, várias imagens de produtos vendidos no supermercado são fornecidas ao sistema de modo que ele possa aprender as características descritivas de cada um.
Isso é feito identificando-se especificidades de cada tipo de fruta ou legume.
“Em seguida, cada tipo de produto é treinado [comparado] contra um outro, em vez de treinar todos contra todos de uma vez.”
O sistema utiliza um método que divide o problema de categorizar muitos produtos diferentes em problemas menores e mais tratáveis.
“Isso pode ser mais bem entendido se for considerada uma situação com três classes, como três frutas diferentes, por exemplo, laranja, maçã e abacaxi”, diz Rocha.
Isso é feito para as diversas combinações de produtos, tomando-se dois de cada vez.
Diversas outras possibilidades podem existir.
Por exemplo, o sistema poderia ser treinado para comparar um tipo de produto contra todos os outros.
Candidatos na balança - Quando o sistema entra em operação, começa a fase de teste.
A cada imagem capturada e fornecida para classificação ele extrai o mesmo conjunto de características do vegetal.
Elas são comparadas com aquelas armazenadas previamente na etapa de treinamento.
Com isso, ele poderá fornecer ao operador do caixa uma lista de candidatos prováveis a ser uma determinada fruta ou legume.
Após a confirmação do funcionário, basta verificar o preço do quilograma do produto e multiplicar pelo seu peso.
Essa forma de resolver o problema é a grande inovação do sistema, que resultou em uma patente depositada no Instituto Nacional de Propriedade Industrial (INPI).
Segundo Rocha, os sistemas existentes são diferentes e menos precisos.
Há, por exemplo, um nos Estados Unidos, chamado VeggieVision.
“Esse sistema extrai o fundo, identifica o tamanho dos objetos independentemente do número deles na cena e compara com as referências”, explica Rocha.
“Ele se baseia em propriedades de cor, textura e densidade, o que requer informações extras da balança.”
Na comparação do índice de acerto na classificação de frutas e legumes, o VeggieVision perde para o sistema brasileiro.
“O índice de acerto do similar americano, mostrando os quatro pro­dutos mais prováveis ao caixa, é de 95%”, diz Rocha.
“Enquanto o nosso, mostrando as duas respostas mais prováveis, é de 99%.”
Para Rocha, uma comparação mais completa também deveria levar em conta outros fatores.
Outra desvantagem do VeggieVision é que ele incorpora no equipamento de aquisição dos dados mecanismos especiais para lidar com variações em iluminação e supressão de reflexões provocadas pela luz na balança e nos sacos plásticos.
Em um cenário real, tais mecanismos podem encarecer a adoção do produto pelo supermercado.
O próximo passo é desenvolver um protótipo físico.
Por enquanto, o que foi desenvolvido é um software e algoritmos para a identificação de frutas e legumes.
Para testar a eficiência desse sistema, Rocha e a equipe usaram uma câmera digital para capturar 2.633 imagens de 15 diferentes espécies, entre as quais cebola, laranja, limão, melancia, pera, maçã, caju, quiuí e batata, expostas para venda na Central de Abastecimentos de Campinas (Ceasa).
“No momento estamos negociando uma parceria com uma empresa americana para dar continuidade ao projeto”, revela Rocha.
O objetivo agora é melhorar as etapas de separação de variedades dentro de um mesmo tipo de produto, tornando o sistema capaz de diferenciar, por exemplo, dois tipos de banana, como a nanica e a prata.
Além disso, os pesquisadores querem incorporar o aprendizado em tempo de operação, ou seja, que a cada resposta confirmada pelo operador do caixa o sistema aprenda com essa confirmação, de modo a ter mais qualidade em classificações futuras.
“A última etapa do projeto será integrar o nosso sistema aos existentes nos supermercados baseados em códigos de barra e conectados às impressoras fiscais”, explica Rocha.
> Artigo científico
ROCHA, ANDERSON; HAUAGGE, DANIEL, C.; WAINER, JACQUES; GOLDENSTEIN, SIOME.
Automatic fruit and vegetable classification from images.
Computer and Electronics in Agriculture (Compag).
v.
70, n.
1, p.
96-104.
2010.
O PROJETO
Orientador
Siome Klein Goldenstein - Unicamp
Anderson de Rezende Rocha – Unicamp
Investimento
R$ 95.443,92 (FAPESP)
Humanidades > História
Pesquisa discute a polêmica questão do banzo como "nostalgia mortal" dos escravos
Carlos Haag
"Vai com a sombra crescendo o vulto enorme/ Do baobá.../ E cresce na alma o vulto de uma tristeza, imensa, imensamente...”, escreveu o poeta parnasiano Raimundo Correia no soneto Banzo.
Segundo a pesquisadora, a análise histórica da enfermidade reafirma a necessidade de desfazer explicações simplificadoras sobre os males de escravos, seja o banzo, seja a sua forma extrema, o suicídio, como decorrentes dos “desgostos provenientes do cativeiro”, fórmula usada no século XIX para encobrir a natureza violenta da relação entre escravos e senhores.
Na história do banzo, então, se cruzam várias rotas da história: histórias da psicopatologia, do tráfico transatlântico de escravos e das doenças.
“A enfermidade sempre aparece numa dupla posição: ela é uma entidade clínica, uma variação da nostalgia europeia nos trópicos, associada a outras doenças dos negros e, ao mesmo tempo, não se dissocia dos debates políticos sobre o cativeiro negro”, observa a pesquisadora.
Segundo o Vocabulário, de Bluteau, de 1712, um jogo está banzeiro quando nem uma das partes ganha, uma indefinição enervante.
“A história do banzo remete a um jogo assim, de escravos contra senhores, da vida contra a morte, em longa e tensa peleja.”
Curiosamente, o conceito de banzo deve sua origem a uma formulação europeia sobre a nostalgia como doença.
A melancolia seria uma indisposição por se estar ausente do lar que se transformava em enfermidade mortal.
Até o célebre Phillipe Pinel dedicou--se ao tema na Encyclopédie méthodique.
“Certamente, os postulados dos vários médicos militares e outros cientistas foram estendidos para os africanos escravizados.
Assim, pode-se considerar o banzo como uma aplicação do conceito de nostalgia, desenvolvido na Europa”, diz a autora.
“Seu trabalho foi a primeira publicação em língua portuguesa a se ocupar da saúde dos escravos e é a principal fonte para as descrições do banzo no século XIX”, diz Ana Maria.
Destacando as ligações entre as enfermidades mortais e o péssimo tratamento dado aos cativos, Oliveira Mendes assinala que, mesmo bárbaros, os africanos eram sinceros e constantes nos afetos.
O banzo é apresentado como uma “gravíssima doença, causada pela exacerbação do sentimento de saudades”.
Essa imagem do banzo como fruto da crueldade do tráfico estendeu-se à primeira metade do século XIX e foi incorporada às narrativas de viagem, aos compêndios de medicina tropical e a teses de medicina.
“É a vocação do banzo para ser um tipo de ‘enfermidade-argumento’, mobilizada na luta contra a escravidão”, lembra a autora.
Sigaud, em Do clima e das doenças do Brasil (1844), lançado pela primeira vez em português este ano pela editora Fiocruz, considerava o banzo como uma doença mental, uma variante da nostalgia-melancolia desencadeada por causas morais tais como as saudades da África ou o ressentimento por castigos injustos.
Já Martius, em Natureza, doen­ças, medicina e remédios dos índios brasileiros (1844), faz uma comparação entre o banzo do negro e do índio, afirmando que em ambos a melancolia reina como causa da morte, com a ressalva de que os negros pareciam sentir mais do que os indígenas os sentimentos dolorosos, já que estes últimos seriam frios e distantes em oposição aos africanos, emotivos e passionais.
Joaquim Manuel de Macedo, em sua monografia sobre a nostalgia, escrita em 1844 (o mesmo ano da publicação de A moreninha) como tese apresentada à Faculdade de Medicina do Rio de Janeiro para a obtenção do título de doutor, considera o banzo como uma moléstia mental originada das saudades da pátria, tendo como sede o cérebro.
“Identificado com a classe senhorial, o escritor romântico não demonstra simpatia alguma pelos escravos, mas pensava que a nostalgia dos negros merecia ser estudada, pois a considerava como potencial ameaça à economia nacional”, relata a pesquisadora.
Além dos três, outros estrangeiros trataram da questão da morte voluntária entre escravos no século XIX: Debret, Henry Koster, Rugendas, Thomas Ewbank, Robert Walsh, F.
Dabadie, entre outros.
“Depois desse interesse, o banzo permanecerá quase adormecido até os anos 1930 e 1940, quando os chamados estudos afro-brasileiros o recolocaram como potencial objeto de investigação.
Ele será tomado como algo real, uma doença um pouco misteriosa, mas sem muita problematização”, conta a autora.
Lar - Surge mesmo uma nova etimologia para a palavra: banzo seria ligado ao quimbundo mbanza, aldeia, e assim significaria a “saudade da aldeia” e, por extensão, do lar.
“A origem africana da palavra me parece um pouco incerta.
No Vocabulário, de Bluteau, por exemplo, a palavra “banzar” aparece como a ação de ‘pasmar com pena’ e “banzeiro” seria algo ‘inquieto, mal seguro’.
Há quem acredite na origem portuguesa da palavra.”
Em 1933, o conceito reapareceu nas páginas finais de Casa-Grande & Senzala (1933), de Gilberto Freyre, cuja visão marcou os relatos modernos da palavra: “Não foi de todo alegria a vida dos negros.
Houve os que se suicidaram comendo terra, enforcando-se, envenenando-se.
O banzo, a saudade da África, deu cabo de muitos.
Houve os que de tão banzeiros ficaram lesos, idiotas”, escreveu Freyre.
Em 1939 começaram a surgir visões médicas da moléstia, como a do parasitologista Manoel Augusto Pirajá, que afirmava ser o banzo uma forma da doença do sono, a tripanossomíase africana, hipótese descartada atualmente.
A produção historiográfica dos anos 1960 e 1970, contestando o que se chamou de “mito da escravidão branda”, preconizado por Freyre, enfatizou o caráter violento das relações entre senhores e escravos e deu nova acepção ao banzo.
Os suicídios seriam sinais de rebelião individual, assim como os quilombos e as insurreições, de rebeldia coletiva”, explica a pesquisadora.
Para ela, porém, seja na perspectiva de Freyre, seja nesta, mais engajada, se deu pouco espaço aos fatores subjetivos envolvidos nas ações dos sujeitos históricos.
Assim, o suicídio cativo pode ser visto também, mas jamais unicamente, como forma de protesto ou fuga da situação de cativeiro, sempre considerando a complexidade da experiência do cativeiro e a capacidade humana de descobrir formas de viver em situações adversas.
“Atribuir a motivação para a morte apenas à condição cativa é uma abordagem simplista.
Os atos suicidas são manifestações extremas que não podem ser reduzidas a uma explicação única, seja ela sociológica, antropológica ou psicopatológica”, assegura o historiador Saulo Veiga Oliveira, que analisou a questão no artigo “O suicídio de escravos em São Paulo”, publicado na revista História, Ciências, Saúde – Manguinhos.
“Basta ver que o alto índice de suicídios entre escravos nas últimas duas décadas da escravidão é, em geral, atribuído aos ‘desgostos do cativeiro’, como reação à condição servil.
Mas há muitos outros motivos: problemas com a Justiça ou o medo de castigos impostos pelo senhor.”
Assassinatos - “O índice de ‘mortes voluntárias’ entre escravos, quando comparado ao de homens livres, era duas ou três vezes mais elevado e, em geral, atribuído ao banzo”, afirma o historiador Renato Pinto Venâncio, da Universidade Federal de Ouro Preto e autor de Ancestrais: uma introdução à história da África Atlântica (Editora Campus).
“Mas, como todo testemunho do passado, isso deve ser lido com olhos críticos: o registro de suicídio pode encobrir assassinatos praticados por senhores.
Isso não implica diminuir o banzo como uma das expressões trágicas da loucura comum a milhões de pessoas vítimas do tráfico de escravos.
A divulgação desse sofrimento nos jornais deve ter contribuído para a formação da sensibilidade abolicionista na sociedade imperial.
Daí se entender o banzo como uma forma não intencional de protesto político, um exemplo primário de luta pela não violência.”
Os números esconderiam outras motivações.
“Os homens livres ocultavam seus casos procurando evitar sanções morais e religiosas, que impediam o sepultamento em cemitérios, o que pode explicar o número elevado de mortes de cativos”, explica o historiador Jackson Ferreira, da Universidade Federal da Bahia e autor do artigo “Por hoje se acaba a lida: suicídio escravo na Bahia (1850-1888)”.
“Os atos suicidas foram mais que expressão e mecanismos de desespero, mas formas de negociar melhores condições, de resistir às condições de cativeiro ou libertar-se dele, abandonando definitivamente esta ‘terra de vivos’, como escreveu o escravo Timóteo em sua nota de suicídio.”
Ana Maria Oda está pesquisando atualmente o curioso “suicídio por ingestão de terra”, citado com frequência por viajantes, no projeto Geofagia e escravidão, financiado pelo Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) e vinculado ao Grupo de Pesquisa Escravidão, Raça e Saúde, sediado na Casa de Oswaldo Cruz, Fiocruz.
“A pica (alteração do hábito alimentar que inclui a ingestão de terra ou barro – a geofagia –, de cal, madeira etc.) é interpretada como uma deliberada ação em direção à morte, um método de suicídio lento dos negros escravos”, diz a pesquisadora.
Debret retratou escravos com máscaras de ferro colocadas para evitar a prática.
“A geofagia como suicídio não se sustenta.
Não se determinaram as suas consequên­cias sobre a saúde, más ou boas.”
O PROJETO
Modalidade
Ana Maria Oda - UFScar
Investimento
R$ 230.994,90 (FAPESP)
Humanidades > Música
Canções que são para sempre
Tango, bolero e fado permanecem vivos por causa de sua ligação com as mídias eletrônicas
Joselia Aguiar
Antes havia o disco de 78 rotações e o rádio; depois o vinil; e hoje o CD e o MP3.
Mudam as mídias, mas algumas canções, apesar de antigas, permanecem.
Como Carinhoso, de Pixinguinha, I’ve got you under my skin, de Cole Porter, Por una cabeza, de Carlos Gardel e Alfredo Le Pera.
Gêneros que passaram décadas esquecidos voltam a fazer sucesso, como o tango.
E algumas interpretações, embora ligadas a uma época específica, são sempre lembradas.
Acaso existiria algum, ou talvez mais de um, traço particular em comum que lhes garanta a sobrevida?
“Há músicas que insistem em não morrer”, diz.
Seu projeto A canção das mídias: memória e nomadismo, o nome atual, é desenvolvido no núcleo Musimid, que faz parte do Departamento de Música da Escola de Comunicações e Artes da Universidade de São Paulo.
E o que seria uma “canção das mídias”?
A esse conceito Heloísa Valente recorre para definir um tipo de canção que difere dos demais que o precederam por impor condições distintas de escuta e performance.
Parece óbvio, pois é a canção que conhecemos.
Porém esse tipo de canção é recente, se se pensar que o rádio e o registro fonográfico têm cerca de um século apenas.
“A canção é o gênero musical mais presente nas mídias, desde que estas existem; e a presença da canção é crescente.
A canção das mídias pode ser aquilo que se denomina como ‘música popular urbana’, mas também inclui, por exemplo, árias de ópera e até canções de origem tradicional”, explica a pesquisadora.
Em mais de uma década de documentação e análise do material coletado, o projeto A canção das mídias já obteve algumas respostas.
A primeira é que há, sim, uma estrutura musical que favorece a permanência.
“Canções que têm um grau maior de complexidade não raro permitem aos arranjadores, músicos e intérpretes efetuar mudanças, das mais sutis às mais drásticas”, explica a pesquisadora.
Ou seja, quanto mais elaborada uma canção, mais poderá ser renovada.
Essa complexidade, segundo ela, pode ser verificada em elementos como densidade harmônica, perfil melódico, formulação rítmica e outros elementos da forma musical.
Porém, não são somente as obras de maior complexidade musical que sobrevivem.
“As ‘modas’, criadas pelo hit parade, fazem com que títulos consagrados em determinado gênero se tornem conhecidos em outro”, diz Heloísa Valente.
Um exemplo é o samba Vingança, de Lupicínio Rodrigues, que se tornou Venganza, em forma de tango, bem talhado ao gosto portenho.
Caminhemos, de Herivelto Martins, também estourou nas paradas de sucesso em sua versão hispânica, Caminemos, com o Trio Los Panchos.
“O sucesso é o motivo para que sejam criadas as novas versões”, reforça a pesquisadora.
É comum, hoje, que as canções reapareçam no formato techno, que é o atual.
Dos gêneros que estuda, encontrou não apenas o electrotango, mas também o fado electrónico, nos quais as gravações-matrizes são manipuladas eletroacusticamente.
A sobrevivência das canções pode ocorrer também devido a um traço que a pesquisadora denomina de “autoridade da performance”.
Para explicar melhor: há intérpretes – ou compositores e letristas, em menor frequência – que adquirem notoriedade com determinados hits, e essa combinação de intérprete e canção favorece sua presença na paisagem sonora.
Emoções, de Roberto e Erasmo Carlos, é um desses exemplos.
É nessa categoria que ela enquadra também intérpretes e canções como Frank Sinatra e I’ve got you under my skin, Yves Montand e Feuilles mortes, Nat King Cole e Stardust.
Estabelecem-se, assim, como standards marcados pelas vozes que os interpretaram.
As músicas se fixam na memória de uma comunidade, de maior ou menor extensão, também devido a suas relações simbólicas, como explica a musicóloga.
Em Portugal, a canção tradicional Grândola, vila morena, composta e cantada por Zeca Afonso, serviu como senha para a instauração da Revolução dos Cravos, em 1975.
No Brasil, O bêbado e o equilibrista, de João Bosco e Aldir Blanc, consagrou-se na voz de Elis Regina como símbolo da reabertura política, no começo dos anos de 1980.
Pouco depois, Coração de estudante, de Milton Nascimento, associou-se à campanha das Diretas-já, a Tancredo Neves e à volta da democracia brasileira.
“Há nesses casos fatos memoráveis, de origem sociocultural, que acabam por determinar essas obras como ‘lugares de memória’, no sentido postulado pelo historiador Pierre Nora.
Tornam-se, de um modo ou de outro, história.
Na maioria dos casos, a vinculação se faz diretamente pela letra da canção, na mensagem veiculada por ela”, acrescenta.
Por fim, rituais de calendário e festas também têm seu próprio repertório, capaz de atravessar gerações: Noite feliz, de Gruber, e Máscara negra, de Zé Ketti, são dois exemplos para Natal e Carnaval, respectivamente.
Ainda há muito a estudar, diz Heloísa Valente, que concentrou mais as pesquisas no tango e no fado.
Como resultado, publicou As vozes da canção na mídia (Via Lettera/Fapesp, 2003), organizou Música e mídia: novas abordagens sobre a canção (Via Lettera; Fapesp, 2007), Canção d’Além-mar: o fado e a cidade de Santos (Realejo/ CNPq, 2008); Canção d’Além-mar: o fado na cidade de Santos: sua gente, seus lugares (Realejo/ FAPESP, 2009) e produziu o documentário Canção d’Além-mar: o fado na cidade de Santos, pela voz de seus protagonistas (2008).
Em fase final de preparação, está Donde estás, corazón?
O tango no Brasil, o tango do Brasil.
Dos três gêneros, o bolero é aquele em que levantamento e análise devem ainda avançar.
O estudo dos três gêneros a partir de sua característica “nômade” – conceito baseado em Paul Zunthor (1915-1995), scholar de origem suíça que produziu obras importantes sobre o tema – é um dos grandes desafios da fase atual da pesquisa.
Cada um dos gêneros “viaja” e assume novas feições, às vezes estilos diferentes e simultâneos.
De origem ainda pouco esclarecida, apesar do esforço de seus vários estudiosos, o tango, por exemplo, contém elementos da habanera cubana e do flamenco, combinados à tradição dos payadores gaúchos.
É um gênero característico de uma região específica da Argentina, a foz do rio da Prata, o eixo compreendido entre Montevidéu e Buenos Aires.
Para lá seguem os músicos argentinos, para gravar seus discos e fazer turnês de música e dança pelas metrópoles circunvizinhas.
As bandas vestem-se com trajes gaúchos e dão títulos em espanhol às composições.
Logo foi escrito com letras em idiomas locais, como francês, alemão e grego.
Entre as décadas de 1930 e 1940, as big bands consagram um novo tipo de tango.
O estilo de cantar e de dançar se modifica, com arranjos modernos ou híbridos.
Os filmes de Hollywood que apresentam o tango contribuem para divulgar uma visão estereotipada, sinônimo de música apaixonada, sensual e extravagante.
Tal influência se propagaria em todos os cabarés berlinenses: é o que se vê no clássico O Anjo Azul, de Josef von Stern­berg.
Da Europa, alcançará a América do Norte e Oriente.
Em alguns casos, compositores e letristas brasileiros fizeram os daqui de acordo com os estilemas (marca distintiva do estilo de um autor) do tango portenho.
Existe, porém, uma variante do tango que surge no Brasil e que teve, por sua vez, outros desdobramentos, de acordo com a pesquisadora: sofreu influên­cia da habanera, que, por sua vez, se mesclou à polca e ao lundu.
Há quem diga que o tango brasileiro e o maxixe designam um mesmo gênero musical – a palavra “tango” seria usada, assim, para ate­nuar o tom lascivo do maxixe.
Um dos seus principais estudiosos, no entanto, o musicólogo Luiz Heitor Correia de Azevedo, autor do clássico 150 anos de música no Brasil (1800-1950), escreveu que o maxixe não constitui gênero musical, mas coreografia.
Em sua origem brasileira, o primeiro tango seria Olhos matadores (1871), de Henrique Alves de Mesquita, como afirma o pesquisador e compositor Bruno Kiefer, autor de Música e dança popular: sua influência na música erudita.
Ainda na mesma década, Chiquinha Gonzaga criará vários tangos brasileiros, de grande sucesso.
“Esses dados provam que o tango brasileiro é anterior ao argentino – o que implica dizer que não há tango, mas tangos.
O fado é outro gênero que tem forte característica “nômade”.
Se hoje é cartão-postal sonoro de Lisboa, tem sua origem no Brasil, como explica José Ramos Tinhorão, autor de obras sobre música popular brasileira que se tornaram clássicas.
Amália Rodrigues, a primeira dama do fado, gravou pela primeira vez no Rio de Janeiro, em 1945.
Santos foi a cidade escolhida pa­ra concentrar essa vertente do projeto A canção das mídias porque é a que abriga, proporcionalmente, o maior número de imigrantes portugueses no país e onde o fado tem até hoje grande presença.
Tem-se, assim, um “fado castiço” que é recomposto incessantemente, pela inserção de novas letras, novas maneiras de performance – o “estilar” dos fadistas-cantores, as improvisações, as condições de apresentação ao vivo.
Em seu estudo, a pesquisadora investigou como o fado deu origem a várias ramificações – fado de revista, fado operário, fado-canção –, criando novos públicos, novos arranjos, novos temas.
O fado imigrante tem, porém, uma vida diferente, como explica a musicóloga: em grande parte da comunidade portuguesa que vive em Santos e em outras partes do Brasil, o fado continuou sendo ouvido e executado como elo com o país de origem.
“Esta canção nômade criou uma ponte imaginária que liga os portugueses imigrantes ao seu país de origem”, afirma Heloísa Valente.
O fado sobrevive, assim, devido a fatores de ordem emotiva, memorialística, intelectual.
E tal per­­­­manência está vinculada também ao tipo de experiência que o seu público tem, no local onde se encontra.
“A recepção do imigrante, pelo menos até o tempo anterior à internet, é diferenciada.
Para essas comunidades, o fado, assim como outros gêneros, é vivenciado, relembrado, reconstituído, tendo como referência as versões mais tradicionais”, afirma a pesquisadora.
O mais curioso é que os registros fonográficos converteram-se em uma espécie de “partitura a ser lida através da escuta atenta”.
A importância das mídias – como rádio em ondas curtas, disco, cinema – na consolidação do gênero também pode ser vista na história do bolero no Brasil.
Seu sucesso é grande a partir da década de 1920, e Augustín Lara (1897-1970) será o primeiro artista mexicano a se apresentar no Brasil.
Jairo Severiano, autor de obras importantes sobre história da música popular brasileira, como os volumes A canção no tempo, diz que se inaugura, assim, um período de mexicanização na cultura brasileira.
“Ainda temos de avançar no estudo sobre o bolero, é a nova etapa da nossa pesquisa”, diz Heloísa Valente.
O projeto
Modalidade
Heloísa de Araújo Valente - USP
Investimento
R$ 178.876,80 (FAPESP)
Carta da Editora >
Incertezas sobre um feito extraordinário
Mariluce Moura - Diretora de Redação
Foi muito forte a minha tentação para dar na capa deste mês de Pesquisa FAPESP a anunciada criação do primeiro organismo artificial do mundo, quebrando, assim, uma das mais respeitadas normas editoriais da revista desde seus primeiros passos: usar como objeto da reportagem de capa exclusivamente temas vinculados à produção científica brasileira.
O feito da equipe liderada pelo famoso empresário-pesquisador Craig Venter, trombeteado para o mundo em 20 de maio, despertava todo meu entusiasmo frente às possibilidades infinitas do conhecimento em sempre surpreender, fascinar e mesmo, de vez em quando, revolucionar profundamente os nossos modos de existência.
O entusiasmo de alguns amigos, por cujas antevisões do avanço da ciência venho experimentando ao longo dos anos o maior respeito, ampliava meu próprio estado de espírito.
E finalmente a capa da usualmente sóbria revista semanal britânica The Economist me forneceu mais um poderoso argumento para a tentação da exceção: ali estava, não o deus criador quase tocando com seu dedo a criatura-homem, cena da famosa pintura de Michelangelo Buonarroti no teto da Capela Sistina, mas o homem criador, laptop sobre a coxa, usando a energia de seu dedo para materializar a criatura-bactéria.
Admirável síntese narrativa visual!
O título, ``And man made life'', seguido pela explicação na linha fina, ``The first artificial organism and its consequences'', não deixava dúvidas sobre o quanto a Economist empenhara seu prestígio no alto significado da pesquisa que havia resultado no primeiro organismo controlado por um genoma artificial, nascido do computador.
Todo o entusiasmo, entretanto, não basta para apagar as incertezas profundas, que certamente ainda vão perdurar por bom tempo, quanto à verdadeira dimensão, o estatuto, digamos, tecnológico, epistemológico ou ontológico da descoberta de Venter e seus colegas.
Seria, por sobre o indiscutível ``salto qualitativo tecnológico que certamente merece ser aplaudido'', como diz Mayana Zatz na página 47 desta edição, algo de natureza revolucionária somente em termos midiáticos?
Ou muito mais que isso?
A rigor, não sabemos.
O feito é indiscutivelmente importante, fantástico mesmo, mas ainda sobram dúvidas que precisariam ser vencidas antes que eu me sentisse à vontade para escolher a exceção em lugar de seguir a regra das capas.
Vou me permitir neste texto, dado que já gastei quase todo o espaço da carta, chamar a atenção somente para mais uma reportagem, justamente a da capa, elaborada pelo jornalista Salvador Nogueira.
A partir da página 16, ela trata do trabalho de um grupo da USP de Ribeirão Preto que conseguiu a caracterização do tipo de dano que a inflamação associada à sepse provoca nas células cardíacas e ainda delineou um caminho promissor para proteger o coração e, dessa forma, levar o corpo a ganhar tempo para retomar o controle na complicada situação de sepse.
Só para lembrar: na sepse, uma infecção generalizada causada por bactéria ou vírus, o organismo lança um ataque desesperado contra suas próprias células.
Quando o coração é o órgão mais atingido, a taxa de óbito decorrente é de 80%, contra 20% na situação de sepse sem dano cardíaco.
Daí por que a defesa do coração é um passo fundamental na luta contra a sepse.
Boa leitura!
Ciência > Biologia
A síntese da criação
Primeiro organismo controlado por genoma artificial prova que o DNA é realmente a receita química da vida
Marcos Pivetta
Quando anunciou no dia 20 do mês passado a criação da primeira linhagem de células viáveis de um ser vivo controlada por um genoma totalmente sintetizado em laboratório, o cientista norte-americano Craig Venter não economizou palavras para descrever o feito.
Lembrou a todos que, nunca antes na história deste mundo, a humanidade tinha sido apresentada a uma criatura desprovida de ancestrais.
Sem pais.
“É a primeira espécie do planeta que se autorreplica cujo pai é um computador”, afirmou o ousado pesquisador-empresário, que, anos atrás, já havia se tornado famoso ao liderar um projeto privado de sequenciamento do genoma humano capaz de rivalizar (e acelerar) o trabalho feito pelo consórcio público.
■ Mayana Zatz: O impacto da transformação de uma vida em outra
Afinal, as informações necessárias para fabricar um genoma, na forma de uma enorme sequência de bases químicas (A, C, T e G), ficam guardadas em computadores.
No caso da variedade natural da bactéria M. mycoides, trata-se da se­quência composta de 1,08 milhão de pares de bases (com cerca de mil genes) presentes em seu único cromossomo.
Foi com essa receita química que se fez, em laboratório, uma cópia sintética do DNA natural da bactéria, seguindo uma série de especificações da equipe do J. Craig Venter Institute (JCVI), instituto fundado por Venter.
O genoma não foi sintetizado como uma única grande sequência de DNA, mas em mais de mil pequenos pedaços.
O conjunto de fragmentos foi inserido numa levedura, onde foram reunidos e retomaram a forma do cromossomo.
Por fim, os cientistas retiraram o genoma sintético da levedura e o transplantaram para as células de uma outra bactéria, a Mycoplasma capricolum.
O cromossomo artificial conseguiu tomar o controle das células receptoras, que passaram a produzir todas as proteínas típicas da M. mycoides.
Dois dias após o transplante, as células deixaram de conter o DNA original da M. capricolum (seja porque ele foi destruído ou diluído no processo de replicação) e apresentavam um único tipo de material genético, o cromossomo sintético da M. mycoides.
Em toda essa operação (ver infográfico na página 46), apenas 14 genes sem muita importância da M. mycoides se perderam ou foram anulados.
“Trata-se de um avanço tanto filosófico como técnico”, disse Venter, resumindo, a seu ver, as implicações da empreitada.
Ápice de um esforço que consumiu US$ 40 milhões e quase 15 anos de pesquisa de um time de 24 pesquisadores do JCVI, entre os quais Ham Smith, Prêmio Nobel de Medicina em 1978, o surgimento da linhagem de bactéria com genoma sintético foi elogiado por cientistas de todo o mundo.
Alguns preferiram situar o trabalho, que foi publicado eletronicamente na revista científica Science, como um grande feito tecnológico, uma mudança de escala na capacidade de o homem modificar o DNA de organismos, mas não como uma revolução científica.
Outros pesquisadores, embora reconheçam o caráter técnico da empreitada, salientam que o trabalho tem, sim, relevância para a ciência.
A visão de três desses cientistas está publicada em artigos especialmente escritos para esta edição de Pesquisa FAPESP, entre as páginas 47 e 51.
O biólogo Fernando Reinach não tira os méritos científicos do experimento de Venter.
Segundo ele, o trabalho é a prova cabal de um conceito, o de que a matéria viva não tem nada de especial e também está submetida às leis da química e da física.
Apenas com a informação do DNA é possível recriar um genoma e, por tabela, uma forma de vida.
“Isso todo mundo já sabia em tese, mas faltava alguém demonstrar na prática essa teoria amplamente aceita”, afirma Reinach.
“Depois da publicação do genoma humano, o trabalho de Venter é o de maior relevância que saiu.
Não há por que tentar relativizar sua importância”, diz José Fernando Perez, presidente da Recepta Biopharma e diretor científico da FAPESP entre 1993 e 2005.
“Ele coroa todo um esforço de entendimento científico do DNA.
Os grandes avanços científicos não vêm de grandes ideias, mas de feitos tecnológicos.”
Reinach também salienta um segundo ponto importante, igualmente de ordem científica, que emerge da análise do artigo na Science.
Até agora, a vida sempre foi vista como algo contínuo.
Todo ser descende de outros organismos semelhantes que viveram no passado.
“O trabalho de Venter demonstra que a vida pode ser interrompida e reiniciada”, afirma Reinach, fazendo alusão ao fato de que a bactéria não tem ancestrais biológicos, é fruto da sequência de letras químicas armazenadas num computador.
A geneticista Mayana Zatz, coordenadora do Centro de Estudos do Genoma Humano da Universidade de São Paulo (USP), comparou a repercussão causada pelo trabalho de Venter a um episódio semelhante ocorrido há 14 anos.
“Esse feito me lembrou da clonagem da ovelha Dolly, por Ian Wilmut, em 1996.
Os dois causaram uma revolução midiática”, escreve Mayana num artigo publicado na página 47.
Grande parte do financiamento das pesquisas do JCVI vem da Synthetic Genomics Inc (SGI), empresa fundada por Venter que fez 13 pedidos de patente sobre métodos usados nos trabalhos com biologia sintética.
Venter diz que o experimento com a M. mycoides vai permitir desenhar microrganismos úteis ao homem, capazes de, por exemplo, produzir vacinas e biocombustíveis.
A empresa petrolífera Exxon já se comprometeu a investir US$ 600 milhões na SGI para o desenvolvimento de algas que consigam produzir etanol.
Segundo a geneticista Lygia da Veiga Pereira, da USP, Venter terá muito trabalho pela frente para exercer a biologia sintética em sua plenitude.
“O maior desafio será desenhar um genoma totalmente novo e escolher que genes serão colocados para que um organismo desempenhe uma determinada tarefa”, diz Lygia.
Ainda que os esforços do cientista americano demorem para gerar frutos palpáveis, a simples presença no ambiente de pesquisa de um sujeito como Venter, polêmico e provocativo, sem dúvida, é vista como salutar por alguns de seus pares.
“Para entender Venter, eu costumo pensar no ser humano como uma criança, uma criança largada numa sala bem grande chamada mundo.
Ela fica mexendo em tudo, às vezes se queima ao colocar o dedo numa tomada, mas outras vezes acaba descobrindo como subir numa cadeira para alcançar as guloseimas lá em cima”, escreve João Meidanis, da Universidade Estadual de Campinas (Unicamp), em artigo na página 48.
> Artigo científico
GIBSON, D.G.
et al.
Creation of a bacterial cell controlled by a chemically synthesized genome.
Science.
Ciência > Biologia
O impacto da transformação de uma vida em outra
Feito tecnológico de Venter causou revolução midiática como a clonagem da ovelha Dolly em 1996
Mayana Zatz
"Criada vida artificial”, “Ciência cria primeira célula sintética” foram algumas das manchetes citando o trabalho de Craig Venter, publicado na revista Science, “Creation of a bacterial cell controlled by a chemically synthesized genome”.
Na realidade foi uma bela obra de engenharia genética, mas não se criou vida.
O que os pesquisadores fizeram foi transformar uma vida em outra, no caso uma bactéria Mycoplasma capricolum em outra, a Mycoplasma mycoides.
Esse feito me lembrou a clonagem da ovelha Dolly, por Ian Wilmut, em 1996.
Os dois causaram uma revolução midiática e podem até ser comparados.
Wilmut transferiu o genoma retirado de uma célula – no caso, da glândula mamária da ovelha Dolly – para um óvulo sem núcleo e, após inseri-lo em útero, gerou um clone de Dolly.
Venter transferiu o genoma de uma bactéria em outra que assumiu o comportamento da primeira.
Afinal, ela é 3 mil vezes menor.
Mas, mesmo assim, foram 15 anos de trabalho envolvendo 24 cientistas, a um custo de US$ 40 milhões.
Nada trivial!
A sequência do genoma da Mycoplasma mycoides já estava disponível no banco de dados do computador.
Mas, para copiar a receita e sintetizar um cromossomo artificial no laboratório, os pesquisadores tiveram que usar leveduras – que também são organismos vivos – e que têm a capacidade de unir pequenos pedaços de DNA.
Uma vez sintetizado o DNA, o próximo obstáculo era inseri-lo em outra bactéria, conseguir que a célula receptora não destruísse o genoma exógeno e o incorporasse como se fosse seu.
Sem dúvida, um grande feito de engenharia genética.
Trata-se de uma revolução?
Midiá­tica, sem dúvida.
A repercussão na imprensa do trabalho de Venter me lembrou da clonagem da ovelha Dolly por Ian Wilmut em 1996.
Vocês devem se lembrar.
“Vão clonar seres humanos!
Estão brincando de Deus.
Vamos criar imediatamente comitês científicos para proibir a clonagem reprodutiva humana.”
Isso era repetido constantemente pela mídia.
Lembro-me muito bem porque fui convidada a fazer parte de um desses comitês, todos preocupadíssimos em proibir a clonagem humana.
Eu estava muito menos temerosa com os riscos de se fazerem clones humanos e muito mais interessada em que se aprovassem as pesquisas com células-tronco embrionárias.
Hoje, 14 anos depois, ninguém mais fala de clonagem reprodutiva humana.
Mas estamos revendo esse filme, agora com o suposto risco de se criar “vida em laboratório”.
O presidente dos Estados Unidos, Barack Obama, já determinou a instituição de comitês de ética para que sejam identificados os limites éticos e minimizados os possíveis riscos.
Por outro lado, o pediatra Carlo Bellieni, no diário do vaticano L’ Osservatore Romano, diz que “a pesquisa é um trabalho de engenharia genética de alto nível, mais um passo na substituição de parte de DNA, mas na realidade não se criou vida”.
Concordo com ele.
Quais são as implicações futuras?
Quais serão as aplicações?
É difícil prever.
No caso da ovelha Dolly a grande revolução foi descobrir que uma célula adulta poderia ser reprogramada e voltar a ser totipotente, o que abriu caminho para as pesquisas com células-tronco.
Já a estratégia para criar a bactéria de Craig Venter poderá permitir aprimorar as técnicas de engenharia genética, produzindo novos microrganismos úteis ao homem, como por exemplo bactérias mais eficientes em degradar a celulose ou o plástico, gerando novas formas de combustível biodegradável.
Ou bactérias intestinais que nos permitissem digerir a celulose tão bem como os ruminantes.
Além disso, ela poderia contribuir para melhorar as técnicas de terapia gênica, corrigindo genes defeituosos em pacientes com doenças genéticas.
Um outro grande feito do qual se falou pouco foi a estratégia utilizada por Venter para que a bactéria receptora não destruísse o genoma da bactéria doadora e o adotasse como se fosse seu.
Essa tecnologia poderia abrir novos caminhos para impedir a rejeição no caso de transplantes alogênicos ou talvez até xenotransplantes.
O futuro dirá.
Deu-se mais um salto qualitativo tecnológico que certamente merece ser aplaudido.
Ciência > Biologia
Craig Venter, um bem necessário
Cientista é como um moleque travesso atrás das guloseimas, sejam elas terminar o genoma humano o mais rápido possível ou fabricar uma bactéria do zero
João Meidanis
Craig Venter está novamente nas notícias de jornais e revistas do mundo inteiro, desta vez por causa do artigo sobre uma célula bacteriana guiada por um genoma que seu grupo sintetizou em laboratório.
Esse é o capítulo mais recente de um projeto ao qual Venter tem se dedicado por mais de uma década: criar um organismo vivo do zero.
E há vários competidores perseguindo a mesma coisa.
Grande descoberta?
Ou impensada ousadia, caixa de Pandora que pode nos levar à autodestruição?
As reações ao artigo que ele publicou na Science vão de rasgados elogios a severos ataques, como sempre parece acontecer com Venter.
Ele é um tipo raro de cientista, incômodo para muitos, mas a meu ver extremamente necessário.
Leia tambémReportagem e artigos
Seu grande parceiro de longa data, Hamilton Smith, ou Ham Smith, como é carinhosamente conhecido, é um gênio da biologia molecular.
No artigo da primeira bactéria sequenciada vemos lá Venter e Smith.
Na diretoria da Celera, a empresa criada para competir com o projeto público (mas lento) de sequenciar o genoma humano, encontramos de novo Venter e Smith.
E agora, neste recente artigo, quem são os cabeças?
Venter e Smith, é claro, agora também incorporando um outro peso-pesado da biologia molecular: Clyde A. Hutchison III, que eles trouxeram para o time em 2003.
Os especialistas lembrarão de Hutchison como um dos pioneiros na introdução de mutações dirigidas em genomas.
Por sua vez, Ham Smith recebeu o Prêmio Nobel muitos anos atrás (1978) pela descoberta de nada mais, nada menos que as enzimas de restrição, uma das ferramentas mais básicas de manipulação genômica.
As enzimas de restrição são para a engenharia genética o que lápis e papel são para estudar na escola fundamental.
Para entender Venter, eu costumo pensar no ser humano como uma criança, uma criança largada numa sala bem grande chamada mundo.
Ela fica mexendo em tudo, às vezes se queima ao colocar o dedo numa tomada, mas outras vezes acaba descobrindo como subir numa cadeira para alcançar as guloseimas lá em cima.
Venter é esse moleque travesso que vai atrás das guloseimas, sejam elas terminar o genoma humano o mais rápido possível ou fabricar uma bactéria do zero.
Se essa busca desenfreada vai nos levar à autodestruição?
É possível.
Mas parece que há algo mais forte dentro de nós, uma curiosidade tão violenta que faz esquecer tudo.
É claro que existe todo tipo de gente no mundo.
Alguns têm esta curiosidade implacável, outros preferem ser meros espectadores da vida sem mexer em muita coisa, e a maioria é um meio-termo entre estes dois extremos.
E, cá entre nós, a espécie humana não vai durar para sempre, com ou sem Venter.
As espécies evoluem, umas desaparecem, outras surgem.
É preciso ter uma visão mais sóbria, menos apaixonada da vida.
Embora tenhamos a tendência natural de achar que o ser humano é central e importante para o mundo, é mais provável que o ser humano seja só mais uma espécie, que veio e irá.
Já passamos por outros episódios onde nos colocamos em posição de destaque não merecida: achávamos que a Terra era o centro do Universo, achávamos que Deus nos tinha criado especiais.
Duas grandes decepções da humanidade, que até hoje muitos não engolem (principalmente a segunda).
Contra proibir pesquisa
Dois papéis fundamentais da ciência são aumentar o conhecimento da humanidade e descobrir novas tecnologias.
Se essas tecnologias serão usadas para salvar vidas, construir armas ou outras finalidades, não compete somente aos cientistas determinar: trata-se de uma decisão da sociedade como um todo, geralmente ao nível dos países.
No mundo atual, cada país tem soberania para decidir como vai utilizar as tecnologias que possui.
Embora exista uma forte pressão internacional contra usos considerados prejudiciais, não há neste momento um organismo multilateral suficientemente forte para fazer valer suas resoluções contra a vontade individual dos países.
Acredito que a geração do conhecimento deve ser livre, desde que respeitadas as normas éticas vigentes.
Do ponto de vista da ética científica, Venter e seu grupo fizeram o que manda o figurino: não utilizaram seres humanos, não impuseram sofrimento desnecessário a cobaias e publicaram seus resultados em veículo de ampla circulação internacional, que inclusive tomou a decisão de disponibilizar esse artigo a qualquer um que tenha acesso à internet, independentemente de ter ou não assinatura da revista.
Dessa forma, todos terão acesso: pesquisadores, estudantes, terroristas, curiosos etc.
Então, gente, relaxa.
Não vamos existir para sempre.
Se vamos sumir mesmo, pelo menos tentemos influenciar um pouco o futuro, dando nosso pitaco sobre quais serão as novas espécies que habitarão o planeta.
João Meidanis é diretor da Scylla Bioinformática e professor titular da Unicamp.
Ciência > Biologia
A biologia sintética e a bioenergia
Como a descoberta de que é possível transferir um genoma criado em laboratório pode afetar as tecnologias para biocombustíveis
Marcos Buckeridge
Já pensou se, a partir da sequência completa do seu genoma, o leitor conseguisse sintetizar o seu próprio DNA, introdu­zi-lo em uma célula humana e depois fazer com que o seu DNA assumisse o comando dessa célula, formando tecidos, órgãos e até uma cópia idêntica de si mesmo, para a qual você poderia transferir suas memórias?
Como no romance de ficção científica de Phillip K.
Dick, que originou o roteiro do filme Blade Runner, parece que pelo menos uma importante prova de conceito foi conseguida.
O J. Craig Venter Institute (JCVI) publicou em 20 de maio no site da revista Science um artigo em que reporta a ativação de um genoma sintético de um microrganismo em outro, a bactéria Mycoplasma mycoides.
A medida de sucesso, nesse caso, foi o fato de que o genoma sintético adquiriu o controle de uma outra célula e essa célula passou a se reproduzir em laboratório.
Eu o ouvi dizer algo similar em uma palestra no último Congresso Mundial de Biotecnologia em Barcelona em 2009.
Um dos grandes desafios que temos atualmente é produzir bioenergia de forma barata e ambientalmente sustentável.
A descoberta do JCVI abre caminho para que pesquisadores consigam microrganismos “engenheirados” que façam o trabalho de produção de etanol ou biodiesel com excelentes padrões.
Aqui no Brasil, no Laboratório Nacional de Ciência e Tecnologia do Bioetanol (CTBE), em Campinas, já estamos “engenheirando” bactérias e fungos com enzimas que atacam a parede celular vegetal e podem ajudar no desenvol­vimento da rota tecnológica da segunda gera­ção do etanol.
Um dos laboratórios do Instituto Nacional de Ciência e Tecnologia do Bioetanol (INCT do Bioetanol), comandado pelo pesquisador Richard Ward, reportou no último workshop do INCT, em abril, ensaios com uma enzima quimérica, ou seja, uma proteína montada artificialmente que tem a capacidade de atacar dois componentes da parede celular ao mesmo tempo, a lignina e a hemicelulose.
Assim, mesmo que não tenhamos feito (ainda) algo tão espetacular como Venter, a bioenergia brasileira já começa a mergulhar na era da biologia sintética.
Há várias vias a escolher e problemas a resolver usando essa tecnologia.
Uma delas é “engenheirar” o metabolismo da Saccharomices cerevisiae, a levedura que usamos para fazer álcool, de forma que ela seja capaz de usar os açúcares de cinco carbonos que vêm das hemiceluloses, algo que ela não faz muito bem.
Com microrganismos, as aplicações da biologia sintética serão bem mais rápidas e deverão produzir resultados impressionantes.
Por outro lado, com organismos mais complexos, podem demorar bem mais.
Mesmo assim, os biólogos já estão se movimentando nesse sentido e o estão fazendo através da compreensão dos organismos como sistemas complexos.
Um grande passo, mas ainda inicial
Colocar um genoma sintético numa célula é, sem dúvida, um passo im­­portante na área da biologia.
Se considerarmos que um gene corresponde, em média, a 10 a 15 kbps (1 kbp equivale a mil bases do DNA), o que o grupo do JCVI fez foi construir um genoma com 600 a mil genes, transferi-lo para uma célula cujo DNA tinha sido retirado, e fazer com que essa célula bacteriana receptora do genoma sintético funcionasse.
É um avanço técnico sensacional e as implicações disso são enormes.
Porém, a dificuldade de aplicar isso em organismos mais complexos é maior ainda.
É provável que na nossa cana-de-açúcar tenhamos aproximadamente o mesmo número de genes que no milho.
No entanto, diferentemente da Mycoplama mycoides, na cana há oito cópias de cada gene.
Isso quer dizer que há, nominalmente, cerca de 240 mil genes interagindo no genoma do organismo e fazendo com que ele funcione perfeitamente bem a ponto de produzirmos o etanol que usamos para encher os nossos tanques.
Se o grau de dificuldade fosse linear em relação ao tamanho do genoma, fazer com a cana o que foi feito com a bactéria M. mycoides seria 400 vezes mais difícil.
Porém há dificuldades adicionais que tornam a relação mais complexa e difícil ainda.
A bioenergia de que necessitamos, em parte por contingência da nossa tecnologia de motores, está armazenada em ligações entre átomos de carbono e a única forma de guardar a energia desse modo é através do processo de fotossíntese.Há
bactérias capazes de realizar fotossíntese e elas são geralmente colocadas como um dos alvos da biologia sintética.
As cianobactérias, por exemplo, são boas produtoras de lipídios que podem funcionar como biodiesel, o que indica que podemos pensar em montar sistemas industriais com elas para produção de bioenergia.
Mas há uma reflexão biológica importante a ser considerada.
Se as cianobactérias são assim tão boas para produzir bioenergia, por que a civilização não é baseada nelas para obter comida e energia até hoje?
Por que nossa comida é baseada principalmente em plantas terrestres?
Uma das respostas é que o aumento de complexidade que houve, com a evolução da multicelularidade e o desenvolvimento de sistemas fotossintéticos cada vez mais eficientes, fez com que as plantas dominassem o planeta.
Dentre elas, as gramíneas, como o milho e a cana-de-açúcar, produziram um dos sistemas fotossintéticos mais eficientes que existem.
Elas têm um sistema de fotossíntese chamado C4, com o qual produzem maior quantidade de biomassa em menos tempo do que outras plantas.
E é por isso que a civilização como a conhecemos é fortemente baseada nessas espécies.
A biologia sintética já vem sendo adotada para alterar a fotossíntese em plantas.
A soja, por exemplo, não tem fotossíntese tão eficiente quanto as gramíneas.
Mas um grupo internacional de pesquisadores já vem traçando estratégias de como fazer para “implantar”, utilizando biologia sintética, um sistema C4 nas folhas dessa leguminosa.
Venter deu um grande passo, mas ainda falta muita investigação e criatividade para que possamos realmente quebrar o código da complexidade que a vida esconde.
Há um grande número de pesquisadores, inclusive no Brasil, se movendo na direção do uso da biologia sintética como principal arma para desenvolver novas biotecnologias.
O que vem por aí promete ser extremamente divertido e interessante.
Marcos Buckeridge é um dos coordenadores do programa Bioen-FAPESP e diretor científico do Laboratório Nacional de Ciência e Tecnologia do Bioetanol (CTBE).
Ciência > Fisiologia
Medo no ar
Biólogos identificam proteínas que indicam a camundongos presença de predadores
Ricardo Zorzetto
Não é preciso ensinar um camundongo ou um rato a ter medo de um gato.
Tão logo começam a andar, os roedores são capazes de reconhecer os sinais deixados no ambiente pelo predador – e perceber quando é hora de sumir.
Depois de realizar experimentos que consumiram três anos de trabalho, o biólogo brasileiro Fabio Papes e dois pesquisadores dos Estados Unidos apresentaram na edição de 14 de maio da revista Cell, num artigo que mereceu a capa do periódico, a resposta para algumas dessas perguntas.
Em parceria com Darren Logan e Lisa Stowers, do Instituto de Pesquisa Scripps, na Califórnia, Papes, pesquisador da Universidade Estadual de Campinas (Unicamp), realizou uma sequência de testes em que colocou camundongos em contato com uma gaze que havia sido friccionada no pescoço de um gato, umedecida com urina de rato ou roçada na pele de uma cobra – três dos predadores naturais dos camundongos.
Em todas as situações a simples percepção do odor aumentava nos camundongos a produção de um hormônio ligado ao estresse e os tornava mais cautelosos: depois de sentir o cheiro de um dos predadores, os roedores passavam a explorar o ambiente com muito mais cuidado.
A importância desse órgão se tornou evidente quando os pesquisadores verificaram que camundongos transgênicos, com uma alteração genética que inativa os neurônios do órgão vomeronasal, não demonstravam medo quando expostos ao cheiro de rato, cobra ou gato.
Tanto os roedores com o vomeronasal ativo quanto os com o órgão desativado evitaram a gaze com naftaleno, sinal de que os neurônios desligados agiam na identificação dos inimigos naturais.
“Esse resultado mostra que o órgão está envolvido na detecção, se não específica, ao menos direcionada, do odor dos predadores”, conta Papes, professor do Instituto de Biologia da Unicamp.
Como secreções de animais de espécies distintas provocaram a mesma reação nos camundongos, os pesquisadores começaram a suspeitar que houvesse algum composto em comum na urina do rato, no muco que recobre a pele da cobra e na saliva que o gato deixa nos pelos ao se lamber.
E deu sorte.
Encontrou na saliva do gato uma proteína – a Feld4 – bastante semelhante à que era a mais abundante na urina do rato, a Mup13 (Major Urinary Protein 13).
Em uma nova bateria de testes, Papes e Darren Logan verificaram que, depois de inalar soluções contendo apenas as proteínas isoladas, os camundongos se mostravam tão cautelosos quanto após sentir odor da urina do gato ou da saliva do gato.
“Essas proteínas funcionam como cairomônios, moléculas liberadas por um organismo de uma espécie que atuam sobre outra espécie, em prejuízo da que as liberou e em benefício da que recebe as informações”, explica Papes, que compartilha com Logan a autoria do artigo da Cell.
Atualmente Papes trabalha na identificação dos circuitos cerebrais ativados por esses odores.
Ele acredita que usando essa estratégia, num futuro talvez não tão próximo, será possível obter um mapa do acionamento sensorial associado a comportamentos como os de defesa, maternal e reprodutivo, entre outros.
“Conhecer como o cérebro reconhece, interpreta e responde a estímulos como os odores”, comenta, “pode até mesmo ajudar a compreender melhor enfermidades relacionadas a alterações sensoriais”.
> Artigo científico
Cell.
v.
141 (4), p.
692-703.
O Projeto
Modalidade
Fabio Papes – IB/Unicamp
Investimento
R$ 725.763,03 (FAPESP)
Ciência > Epidemiologia
Passos incertos
Novos estudos mostram como detectar e reduzir o risco de quedas em idosos
Maria Guimarães
A maior ameaça à saúde e à vida dos idosos circula dentro de casa e nas ruas, sobretudo pela manhã e à tarde.
São os tombos, responsáveis por 61% das admissões em pronto-socorro de pessoas com mais de 60 anos, de acordo com dados de 2007 do Ministério da Saúde.
As quedas são um drama comum entre idosos, mas costumam ser vistas pelo resto da sociedade como inerente ao avanço da idade.
As consequências são sérias demais, porém, para que o problema não seja tratado como questão primordial de saúde pública.
Por volta de 16% das quedas causam fraturas, e a cada quatro idosos internados para cirurgia no fêmur um morre no prazo de um ano, de acordo com o reumatologista Marcelo Pinheiro, da Universidade Federal de São Paulo (Unifesp), um dos coordenadores do Estudo Brasileiro sobre Osteoporose (Brazos), o primeiro a avaliar a extensão do problema no país.
Felizmente, uma série de estudos vem mostrando que exercícios simples podem evitar boa parte desses acidentes e de fato melhorar a qualidade do período da vida que alguns preferem chamar de “melhor idade”.
As consequências mais sérias das quedas se devem à osteoporose, a perda gradual de densidade óssea que amea­ça sobretudo as mulheres.
Ela pode ser a causa inicial da queda – algo aparentemente banal como um movimento súbito estilhaça o fêmur e a pessoa cai muitas vezes sem saber por quê.
Mas em mais de 90% dos casos de fratura associada a quedas o tombo é a causa da fratura, e não vice-versa, de acordo com Pinheiro.
Levando em conta questionários respondidos em 2006 por 2.420 pessoas com mais de 40 anos, o Brazos avaliou quedas recorrentes e fraturas em 150 cidades das cinco re­giões brasileiras.
Entre os adultos entrevistados, 15% dos homens e 30% das mulheres que já haviam sofrido fraturas tinham um histórico compatível com a osteoporose, mas 85% deles e 70% delas não estavam informados sobre a doença.
“Muitas vezes a fratura é tratada e não se faz a densitometria para avaliar o estado dos ossos”, conta Pinheiro.
Com base no conhecimento acumulado por outros estudos e nos indícios clínicos, os pesquisadores do Brazos estimam uma prevalência de osteoporose muito maior do que a relatada nos questionários, de acordo com artigos publicados recentemente nos Arquivos Brasileiros de Endocrinologia & Metabologia e nos Cadernos de Saúde Pública.
O problema se torna ainda mais alarmante diante das projeções de aumento na população idosa brasileira ao longo das próximas décadas.
De acordo com o Instituto Nacional de Geografia e Estatística (IBGE), em 2025 o país terá 35 milhões de habitantes com mais de 60 anos de idade, mais de 2 milhões só na cidade de São Paulo.
Entre 2000 e 2050, a previsão é que quase triplique a proporção de idosos em relação à população total – passando de 5,1% para 14,2% –, resultado de uma taxa de natalidade decrescente e uma expectativa de vida maior.
Para o reumatologista da Unifesp, outro achado relevante diz respeito à alimentação.
Nossa dieta é bastante equilibrada em termos de proteínas, carboidratos e gorduras, mas deixa muito a desejar em micronutrientes e vitaminas.
“O brasileiro consome 400 miligramas de cálcio por dia, quando a recomendação internacional é de 1.200 miligramas”, conta.
É um problema cultural, mais do que socioeconômico, já que até os mais abastados, das classes A e B, ingerem cerca de metade do cálcio que deveriam.
Para Pinheiro, uma estratégia interessante seria fortificar alguns alimentos, como é comum em países como os Estados Unidos, ou fazer suplementação de micronutrientes.
Outra deficiência importante, diretamente ligada à incorporação do cálcio nos ossos, é a vitamina D, abundante em peixes como o arenque, o atum e o salmão, além de nozes, amêndoas e azeite.
“Comer esses itens é um hábito do hemisfério Norte, aqui consumimos cinco vezes menos do que a recomendação diária, cerca de dois microgramas por dia.”
“É preciso expor pelo menos os braços e o colo ao sol por no mínimo 20 minutos ao dia, sem protetor solar”, recomenda Pinheiro.
O impacto desses tombos e fraturas na qualidade de vida é dramático, conforme mostram dados do Brazos.
O que causa a morte, no prazo de um ano, de um quarto dos idosos que fraturam o fêmur são as consequências da internação, como úlceras de pressão (escaras), embolia pulmonar e infecção.
Ficar internado também pode causar depressão, abrindo as portas para demências e ampliando a dependência causada pelas limitações físicas.
“É como uma panela de pressão”, compara, “a pessoa estava bem e de repente a fratura faz aflorarem os problemas que estavam latentes”.
Para prevenir a osteoporose, não basta tratar os idosos.
“É uma doença geriá­trica cuja prevenção tem que começar na infância, com dieta correta e atividade física.”
O Brazos, que incluiu adultos a partir dos 40 anos, revelou que os mais jovens não têm consciência do problema iminente e não tomam medidas preventivas.
A principal causa dos acidentes que deixam milhares de idosos praticamente inválidos a cada ano, segundo Pinheiro, é o desconhecimento.
Além da prevenção, que deveria incluir parar de fumar e de beber álcool e café em excesso, hoje existem tratamentos eficazes para manter a densidade óssea.
A osteoporose e a probabilidade de quedas não estão ligadas só pela má sorte – e entender isso pode ser crucial para a prevenção de fraturas.
É que a atividade muscular ajuda a manter os ossos saudáveis.
“Acreditamos que a perda de músculo se dê junto com a perda óssea”, conjectura Daniela.
Ela usou sensores eletromagnéticos para avaliar o equilíbrio de mulheres com osteoporose, com osteopenia – um estágio intermediário de perda óssea – e com ossos íntegros e verificou que quanto mais frágeis os ossos, maior a instabilidade.
“A fraqueza em grupos musculares específicos causa tipos diferentes de instabilidade”, explica Daniela.
Mesmo tendo perdido pouco da massa óssea, as mulheres com osteopenia já mostraram uma oscilação para a frente e para trás igual à que o estudo verificou naquelas com osteoporose, e maior do que nas mulheres sem problemas nos ossos.
À medida que o osso se degrada, outros músculos também perdem massa, o que dá origem a um ciclo vicioso.
De acordo com os sensores, as mulheres com osteo­porose não só balançam para a frente e para trás, mas também para os lados.
O próximo passo, segundo Daniela, é detalhar quais são os grupos musculares mais afetados para delinear treinamentos de recuperação específicos.
Enquanto não se detalha esse mapa dos músculos enfraquecidos, o grupo da reumatologista Rosa Pereira, da Faculdade de Medicina do campus paulistano da USP, comprovou que exercícios físicos de equilíbrio, além de reduzir a incidência de quedas, são eficazes também para melhorar vários aspectos como o bem-estar, as funções físicas e as interações sociais.
Durante o trabalho de doutorado, a fisioterapeuta Melisa Madureira desenvolveu um método para melhorar o equilíbrio de pacientes com osteoporose.
Com séries de exercícios simples – como andar para a frente, de lado, levantando uma perna e o braço oposto, na ponta dos pés e nos calcanhares –, por 30 minutos uma vez por semana, associadas a alongamento e caminhada, ela já conseguiu melhorar a qualidade de vida e reduzir a incidência de quedas nos 30 pacientes do grupo experimental em relação aos 30 pacientes que não fizeram o treinamento, de acordo com artigo já disponível no site da revista científica Maturitas.
Os participantes do estudo também recebiam uma cartilha para fazer os exercícios em casa, melhorando ainda mais os resultados.
“Ao contrário de musculação, que requer acompanhamento individualizado, para esse tipo de exercícios não é necessário supervisão constante.
“Medicar contra osteoporose sem reduzir as quedas não adianta, porque as fraturas continuam acontecendo”, completa.
De fato, não adianta se concentrar apenas na osteoporose, já que inúmeros fatores levam aos tombos.
Um estudo coordenado pelo epidemiologista Evandro Coutinho, da Fundação Oswaldo Cruz (Fiocruz), comparou 250 casos de quedas atendidos em cinco hospitais no Rio de Janeiro a 250 controles com idade, sexo e local de residência semelhantes, e apontou baixo índice de massa corporal, déficit cognitivo, derrames, incontinência urinária, uso de medicamentos benzodiazepínicos e de relaxantes musculares como fatores de risco para quedas com fraturas sérias, segundo artigo de 2008 na BMC Geriatrics.
O grupo não levou a osteoporose em conta porque nos hospitais selecionados não era rotineiro diagnosticar a doença.
“O mais surpreendente foi detectar o efeito dos relaxantes musculares”, conta Coutinho, “a maior parte dos estudos não leva em conta esse tipo de medicamento”.
Esses remédios, muitas vezes prescritos para aliviar dores nas costas dos idosos, podem quadruplicar o risco de quedas.
Já os benzodiazepínicos são usados como tranquilizantes, e costumam ser prescritos para quem tem dificuldade de dormir.
O problema é que causam tonturas, sonolência e reduzem a força e a contração musculares, duplicando o risco de queda e fratura.
“Os idosos têm um metabolismo mais lento, por isso quando acordam ainda sofrem os efeitos da medicação”, explica o epidemiologista, que também se surpreendeu ao verificar que a maior parte dos acidentes acontece de manhã e à tarde e não, como ele esperava, quando a pessoa se levanta no escuro da noite para ir ao banheiro.
Para ele, antes de receitar esses tipos de medicamento aos idosos, os médicos deveriam pesquisar melhor as causas das dores e da dificuldade em cair no sono, em vez de só tratar os sintomas.
E, completa, hoje existem benzodiazepínicos mais adequados aos idosos, que duram menos tempo no organismo.
“A cada 100 idosos, 30 cairão num dado ano”, avalia Coutinho.
Mas o risco é maior para aqueles que já caíram: 60% dos idosos que caem e se machucam voltarão a cair no prazo de um ano, de acordo com dados levantados pelo projeto Saúde, Bem-Estar e Envelhecimento (Sabe), um estudo que acompanha ao longo do tempo as condições de vida e de saúde dos idosos residentes na cidade de São Paulo.
“Uma queda é um indício de que a pessoa pode cair outra vez”, comenta a médica Maria Lúcia Lebrão, da Faculdade de Saúde Pública da Universidade de São Paulo (USP), coordenadora do projeto.
Para a pesquisadora da Faculdade de Saúde Pública, é preciso avaliar com cuidado as causas dos tombos para corrigi-las.
Muitos idosos sentem tonturas e perdem o equilíbrio mesmo sem obstáculos no caminho.
Com menos força muscular e reflexos mais lentos, fica bem mais difícil corrigir posições instáveis e aqueles tropeços que, na juventude, passavam despercebidos.
Somam-se a isso fatores ambientais como calçadas irregulares, sapatos que desafiam o equilíbrio e tapetes escorregadios.
Iniciado em 2000 (ver Pesquisa FAPESP nº 87), o estudo de que já participaram quase 2.500 pessoas acompanha as tendências do envelhecimento do paulistano e agora inicia sua terceira fase.
Dois terços dos entrevistados relataram pelo menos uma queda desde que completaram 60 anos.
Quanto maior a idade, maior o risco de cair, mas o mais surpreendente é que os fatores ambientais são um risco ainda maior do que os anos acumulados: idosos que se mudaram recentemente têm maior risco de cair na casa que conhecem mal do que aqueles que residem há muitos anos no mesmo local e já gravaram na memória os possíveis obstáculos.
O estudo mostrou também que um fator importante em torno das quedas é a síndrome da fragilidade, que tanto pode causar tombos como ser consequên­cia deles.
A síndrome pode ser identificada quando se observa pelo menos três de cinco sinais: perda de peso sem causa, diminuição da força muscular, fadiga, velocidade cada vez menor na caminhada e baixa na atividade física.
Yeda Duarte, da Escola de Enfermagem da USP, vem analisando essa questão em um subprojeto do estudo Sabe coordenado por ela, em colaboração com Maria Lúcia.
A cada seis meses, desde 2008, elas avaliaram idosos a partir dos 75 anos de idade, alternando visitas em domicílio e entrevistas por telefone.
“As mulheres vivem mais tempo do que os homens mas, nesses anos que vivem a mais, muitas delas podem ter uma qualidade de vida pior, uma vez que a sobrevida pode vir acompanhada por períodos de incapacidade”, comenta Maria Lúcia.
Segundo a pesquisa, a população paulistana parece estar se fragilizando mais cedo do que se observa em países desenvolvidos, onde a síndrome é mais frequente depois dos 85 anos.
No estudo da USP foi observado que, em São Paulo, a condição muitas vezes já está instalada desde os 65 anos.
Será preciso incluir idosos mais jovens na pesquisa para entender melhor como a síndrome se instala nessa população.
A fragilidade em si se torna uma limitação séria quando a pessoa não tem forças para manter a rotina normal e leva meia hora para chegar à esquina.
Mas a associação com as quedas torna o problema ainda mais grave, sobretudo quando elas resultam em fraturas que exigem cirurgia, hospitalização e imobilização mais prolongada, que contribui para agravar o quadro de fragilidade.
“É preciso quebrar esse ciclo”, resume Maria Lúcia, que mantém parcerias com o Ministério da Saúde e com as secretarias correspondentes no estado e no município de São Paulo para, a partir da pesquisa, contribuir para implantar intervenções que ajudem a evitar ou reverter a fragilidade.
Academia - Um dos principais agravantes da predisposição às quedas é a falta de força muscular, de acordo com trabalho de André Rodacki, especialista em biomecânica da Universidade Federal do Paraná (UFPR).
Na caminhada comum, explica o pesquisador, a flexibilidade da musculatura dos quadris é essencial para melhorar o controle das pernas, e a força dos músculos extensores do joelho garante passadas mais largas e firmes.
Num estudo com 20 mulheres idosas fazendo exercícios de alongamento direcionados para a região do quadril três vezes por semana, publicado em 2009 na Gerontology, ele mostrou que bastam quatro semanas para melhorar o quanto a pessoa levanta os pés, o tamanho da passada e a velocidade.
Já é um belo passo no sentido de reduzir o risco de tombos, mas não o único.
Quando se trata de evitar que um molho de chaves caia no chão ou de corrigir um tropeço, é preciso que os músculos sejam capazes de gerar força muito depressa, explica Rodacki.
Melhorar essa capacidade, conforme ele mostra este mês na Clinical Biomechanics, envolve treino de potência para os músculos do joelho, fazendo movimentos rápidos num aparelho com pouco peso, um tipo de exercício raramente proposto a idosos.
Ele agora vem pesquisando maneiras mais interessantes de manter uma boa caminhada e um bom equilíbrio.
Não limitado a ossos e músculos, o problema chega também à mente e abala a segurança do idoso.
O medo de cair faz parte do dia a dia de 42% dos homens e 60% das mulheres com mais de 60 anos, de acordo com resultados do Brazos publicados este ano nos Cadernos de Saúde Pública.
“A não ser nos casos de demência, ele sabe o risco que corre.”
Mariana – que trabalha no Departamento de Fisioterapia, Fonoaudiologia e Terapia Ocupacional da USP – também encontrou uma correlação clara entre o medo de cair, medido por um questionário sobre tarefas normais do cotidiano, e dificuldades cognitivas.
Além do medo de cair, Mariana percebeu que a escolaridade tem um efeito importante sobre o risco de quedas, conforme indica a dificuldade em completar o teste cognitivo.
“A média de escolaridade entre os idosos brasileiros é de aproximadamente quatro anos”, afirma.
O estudo mostrou que pessoas com menos anos de estudo têm mais dificuldades em integrar informações, menos memória e coordenação, e portanto um equilíbrio mais precário.
Além disso, completa a pesquisadora, elas têm menor poder aquisitivo e acesso mais limitado a serviços de saúde e medicamentos, o que provavelmente agrava o problema.
A melhor solução, de acordo com a fisioterapeuta, não é mandar os idosos de volta para a escola.
Ela viu que exercícios simples que treinam a integração cognitiva motora – fazer ao mesmo tempo um movimento e prestar atenção em algum ponto no ambiente, por exemplo – tornam os idosos mais ágeis em pouco tempo.
Mariana planeja implantar um sistema de visitas em domicílio que ajude as pessoas mais velhas a integrar as informações de seu próprio mundo.
Para ela, a proposta é viável até financeiramente.
“É muito mais barato para o país fazer uma intervenção pontual uma vez por mês do que manter um idoso hospitalizado com fratura de fêmur.”
Um ponto em comum parece reunir pesquisadores de áreas de especialização diversas em torno da mobilidade e equilíbrio dos idosos: andar pela rua, enfrentando calçadas esburacadas e degraus, não precisa ser mais difícil do que uma gincana com obstáculos e trechos percorridos com as pernas enfiadas num saco.
Medidas simples e eficazes podem devolver vigor e prazer ao dia a dia depois dos 60 anos.
> Artigos científicos
1.
VOOS, M.C. et al.
Relationship of executive function and educational status with functional balance in older adults.
Journal of Geriatric Physical Therapy.
no prelo.
2.
The association between osteoporosis and static balance in elderly women.
Osteoporosis International.
no prelo.
3.
Risk factors for recurrent falls among Brazilian women and men: the Brazilian Osteoporosis Study.
Cadernos de Saúde Pública.
v.
26, n.
1, p.
89-96.
jan.
2010.
4.
BENTO, P. C. B. et al.
Peak torque and rate of torque development in elderly with and without fall history.
Clinical Biomechanics.
v.
25, p.
450-4.
jun.
2010.
Os Projetos
1.
2.
Estudo Sabe-2005: saúde, bem-estar e envelhecimento.
Modalidade
1.
Auxílio Regular a Projeto
2.
Projeto Temático
1. Daniela de Abreu – FMRP/USP
2.
Ruy Laurenti – FSP/USP
Investimento
2.
R$ 472.509,34
Ciência > Ecologia
O amigo oculto da preguiça
Pelo de mamífero abriga um tipo de alga verde que vive em simbiose e não existe em mais nenhum lugar da natureza
Marcos Pivetta
Não é segredo para os biológos que o tom marrom-esverdeado dos grossos pelos das preguiças se deve à presença de organismos clorofilados.
Algas verdes e cianobactérias (algas azuis) escondidas na pelagem ajudam esses lentos mamíferos que vivem trepados nas árvores a se camuflar na mata e despistar seus predadores.
Mas os pesquisadores não imaginavam que essa parte do corpo das preguiças pudesse abrigar um miniecossistema tão variado.
Um estudo filogenético feito com amostras da pelagem de 71 animais, pertencentes às seis espécies de preguiça existentes, encontrou material molecular oriundo de 72 grupos distintos de organismos – desde aranhas, mariposas, besouros e baratas até um grande número de micróbios.
“Havia seres que eram produtores (algas), consumidores (protozoários) e decompositores (fungos) de alimentos”, afirma o ecólogo Adriano Chiarello, da Pontifícia Universidade Católica de Minas Gerais (PUC-MG), um dos autores do trabalho, publicado em 30 de março deste ano na revista BMC Evolutionary Biology.
“Isso não era esperado.”
Outra informação interessante foi a grande incidência de um grupo de algas verdes do gênero Trichophilus, identificadas na pelagem de 73% das preguiças analisadas, independentemente de sua origem geográfica.
O dado reforça a ideia de que há realmente uma antiga relação de simbiose entre as preguiças e as algas.
Esse tipo de mamífero só ocorre nas florestas tropicais da América Central e do Sul e os animais analisados no trabalho eram provenientes de quatro países: Brasil, Guiana Francesa, Costa Rica e Panamá.
Os pesquisadores acreditam que uma espécie de alga verde, a Trichophilus welckeri, descoberta há mais de um século e meio, seja encontrada na natureza apenas nos pelos das preguiças.
“A alga foi descrita em 1841 em amostras da pelagem desses animais e nunca mais foi documentada em outros hábitats”, comenta a finlandesa Milla Suutari, da Universidade de Helsinque, outra autora do estudo.
“Provavelmente ela não está presente em mais nenhum ambiente.”
Se essa hipótese estiver correta, trata-se de uma alga que acabou se desenvolvendo em paralelo à história evolutiva desses solitários escaladores de árvores, talvez estabelecendo uma estreita relação com seu hospedeiro por excelência.
Fonte de nutrientes - A pelagem das preguiças parece ser realmente um bom meio de cultura de algas.
Tem estrias e fissuras e, ao contrário do pelo de outros mamíferos, absorve água.
Além de fornecer um despiste cromático para os mamíferos, as algas talvez sejam uma pequena fonte extra de nutrientes que seriam absorvidos via difusão pela pele das preguiças.
Outras hipóteses ainda não testadas têm sido propostas para explicar essa estreita ligação entre algas e preguiças.
As algas poderiam, por exemplo, produzir substâncias que deixariam os pelos com a textura mais apropriada para o crescimento de bactérias benéficas.
Ou ainda produzir certos tipos de aminoácidos que absorveriam raios ultravioleta, ou seja, atuariam como protetores solares para as preguiças.
As algas do gênero Trichophilus se perpetuam entre as preguiças passando provavelmente das mães para os filhotes, quando estes alcançam algumas semanas de vida, sugere o estudo.
Entre os 19 animais que não abrigavam essas algas, sete eram bebês.
Talvez no momento em que as amostras de pelo foram recolhidas para o estudo esses tenros filhotes ainda não tinham tido tempo de contato suficiente com as mães para adquirir o amigo verde.
As preguiças se dividem em dois gêneros: o Bradypus, em que estão as chamadas preguiças de três dedos, com quatro espécies (B.
tridactylus, B. torquatus, B. variegatus e B. pygmaeus); e o Choloepus, as preguiças de dois dedos, com duas espécies (C.
didactylus e C. hoffmanni).
A presença das algas verdes também parece seguir esse padrão, visto que as espécies de Trichophilus identificadas num gênero são aparentemente distintas das achadas no outro.
Com exceção da B. pygmaeus, existente apenas numa ilha do Panamá, as outras cinco espécies são encontradas no Brasil.
Uma delas, a B. torquatus, popularmente conhecida como preguiça-de-coleira e que está ameaçada de extinção, só existe na Mata Atlântica brasileira.
Por ser um bicho exclusivo das florestas nacionais, a preguiça-de-coleira foi a única representante brasileira no estudo sobre algas que vivem na pelagem desse mamífero.
Embora tenham sido identificados vários tipos de algas terrestres no pelo da B. torquatus, exemplares do gênero Trichophilus não foram achados.
Também na C. didactylus algas desse gênero não foram encontradas.
Mas, como havia amostras de pelos de somente dois exemplares dessa espécie, não foi possível fazer uma análise mais definitiva nesse caso.
> Artigo científico
SUUTARI.
M. et al.
Molecular evidence for a diverse green algal community growing in the hair of sloths and a specific association with Trichophilus welckeri (Chlorophyta, Ulvophyceae).
BMC Evolutionary Biology.
Ciência > Astrofísica
O segredo de Perseu
Simulações ajudam a explicar temperatura elevada do gás em aglomerados de galáxias
Salvador Nogueira
Uma galáxia gorda, velha e decadente que parece ter tomado emprestado gás de suas vizinhas para voltar a fabricar estrelas está ajudando um grupo de astrônomos a decifrar os mistérios dos aglomerados de galáxias, os tijolos formadores das maiores estruturas do Universo.
Com a forma de uma esfera achatada, a galáxia se localiza na direção da constelação de Perseu, o mitológico herói grego que decapitou a Medusa, e é imensa: abriga de 10 a 100 vezes mais matéria do que a nossa galáxia – a Via Láctea, formada por cerca de 200 bilhões de estrelas – e mantém outras aprisionadas gravitacionalmente ao seu redor.
Conhecido como aglomerado de Perseu, esse grupo de galáxias tem uma característica marcante que há tempos intriga quem o estuda: é permeado por uma gigantesca nuvem de gás muito rarefeito e quente, com algumas regiões apresentando temperaturas bem mais elevadas do que seria de esperar.
As leis da física preveem que, à medida que o gás das galáxias vizinhas é atraído pela gravidade rumo à galáxia central – no caso, a NGC 1275, distante 235 milhões de anos-luz da Terra –, sua densidade deve aumentar enquanto sua temperatura diminui acentuadamente.
“Como o gás se torna mais denso próximo ao centro do aglomerado, as partículas que o formam colidem mais facilmente umas com as outras e perdem energia na forma de radiação”, explica a astrofísica Elisabete de Gouveia Dal Pino, que vem estudando o aglomerado de Perseu nos últimos anos.
Assim, quanto maior a densidade e a proximidade da galáxia central, mais frio deve se tornar o gás.
Isso, no entanto, não é bem o que acontece com Perseu.
Esse efeito só se justificaria se algo estivesse reaquecendo o gás na região mais central do aglomerado, equilibrando a perda de calor.
Há algum tempo os pesquisadores até têm um candidato: um gigantesco buraco negro, com massa equivalente à de centenas de milhões de estrelas como o Sol, situado bem no centro da NGC 1275.
Os buracos negros são objetos tão densos e compactos que impedem que qualquer coisa escape de sua superfície, inclusive a luz.
Mas na sua vizinhança é liberada muita energia.
Antes de ser sugada e absorvida, a matéria que espirala ao redor do buraco negro é acelerada pela gravidade.
Parte dela, auxiliada por campos magnéticos, escapa em dois feixes estreitos que saem dos polos do buraco negro, originando os jatos de partículas que se deslocam a velocidades próximas à da luz.
Esses jatos emitem ondas de rádio que são detectadas pelos astrônomos.
Imagens feitas a partir de outra forma de radiação, os raios X, mostravam que as proximidades do buraco negro da NGC 1275 – região do espaço também conhecida como núcleo galáctico ativo por emitir mais energia do que o restante da galáxia – liberavam energia suficiente para manter o gás aquecido na porção mais central do aglomerado.
Mas havia um mistério: como as temperaturas do gás podiam ser mais ou menos homogêneas, se os jatos de radiação gerados a partir do buraco negro eram tão estreitos?
Ao conduzir simulações em computador, o grupo coordenado por Elisabete Dal Pino e Zulema Abraham, pesquisadoras do Instituto de Astronomia, Geo­física e Ciências Atmosféricas da Universidade de São Paulo (IAG-USP), na capital paulista, encontrou uma possível resposta.
“As temperaturas poderiam ser as observadas, caso o núcleo galáctico ativo estivesse em precessão [mudança de inclinação no eixo de rotação]”, afirma Elisabete.
A ideia pode ser traduzida assim: para manter a temperatura aproximadamente homogênea, é preciso que o eixo de rotação do objeto central varie de inclinação e os jatos oscilem distribuindo melhor a energia.
Ou, de modo mais simples, isso pode acontecer se o buraco negro bambolear como um pião que perde velocidade.
As simulações realizadas por Diego Falceta-Gonçalves, da Universidade Cruzeiro do Sul (Unicsul), em São Paulo, produziram resultados similares aos observados na natureza quando o ângulo de variação do eixo era grande: 60 graus.
No artigo do Astrophysical Journal Letters em que apresentaram os resultados no início de 2010, os pesquisadores explicam: como os jatos oscilam com o tempo, a energia liberada é aproximadamente igual em todas as direções.
É como se os feixes de radiação funcionassem como as pás de uma batedeira que misturam os ingredientes do bolo para tornar a massa homogênea.
Mas essa pode não ser a única explicação.
Em meados de 2008, Elisabete Dal Pino visitava a Universidade de Wisconsin em Madison, nos Estados Unidos, quando o astrônomo americano John Gallagher mostrou a ela um resultado que havia acabado de obter e nem sequer havia publicado.
Gallagher e seu grupo tinham feito medições dos filamentos de gás que existem ao redor da NGC 1275.
“Ele ficou intrigado porque eles obtiveram mapas das velocidades dos filamentos e perceberam que alguns deles estavam se afastando da galáxia, e não se aproximando, como seria o esperado”, conta a astrofísica.
O resultado, publicado no ano seguinte na Nature, era uma medição inesperada.
Indicava que alguma força estava contrabalançando a gravidade e empurrando o gás para fora da NGC 1275.
Além disso, forças magnéticas faziam os filamentos arquear.
Era pouco provável que o núcleo galáctico ativo, por mais poderoso que fosse, estivesse produzindo o fenômeno sozinho.
O que estaria acontecendo?
“Foi aí que eu tive a ideia das supernovas”, diz a pesquisadora brasileira.
Supernova é o nome que se dá a uma estrela com massa muito elevada que consumiu todo o seu combustível e explodiu.
É um dos eventos mais energéticos do Universo.
Uma série de supernovas poderia explicar o formato dos filamentos ao redor da galáxia central do aglomerado.
Em outra série de simulações, dessa vez em parceria com John Gallagher e Alex Lazarian, ambos de Wisconsin, Falceta-Gonçalves e Elisabete mostraram que o gás em queda proveniente das galáxias vizinhas poderia produzir uma onda de choque na superfície da NGC 1275 e gerar um súbito episódio de formação estelar.
Estrelas com muita massa queimam seu combustível mais rapidamente do que astros menores como o Sol, que precisam de bilhões de anos para esgotá-lo.
Por isso, poderia haver uma onda de explosões de supernovas uns poucos milhões de anos após o processo de formação estelar.
Com auxílio de computadores, os pesquisadores reproduziram o que acontecia 120 milhões de anos – simulados, é claro – após o nascimento das estrelas.
O trabalho, também publicado no Astrophysical Journal Letters, indicou que a interação da radiação emitida pelo núcleo galáctico ativo com as turbulências geradas pelas supernovas produz um padrão de filamentos muito parecido com o observado ao redor da NGC 1275.
“Cada simulação, em resolução máxima, de 100 milhões de pixels, demora cerca de 20 dias para ser completada”, conta Falceta-Gonçalves, que conduziu a maior parte dos testes e é o primeiro autor dos artigos.
Esses trabalhos apresentam, sem dúvida, explicações plausíveis para os mistérios da NGC 1275.
Mas como saber qual é a real causa da distribuição homo­gênea de temperatura do gás e dos filamentos observados ao redor da galáxia?
Uma das formas de comprovar essas explicações seria procurar, com o auxílio de telescópios, sinais deixados por estrelas com massa muito elevada e por supernovas nas regiões mais externas da NGC 1275.
Outra estratégia, mais ao alcance da equipe brasileira, é realizar novas simulações, dessa vez combinando o efeito da precessão do núcleo galáctico ativo com a explosão das supernovas nas bordas da galáxia e verificar o que acontece.
De toda forma, já se avançou um pouco mais na compreensão da dinâmica de aglomerados de galáxias como o de Perseu – e, por extensão, do aglomerado do qual faz parte a Via Láctea.
Esses tijolos do Universo, que numa escala maior se organizam em superaglomerados, ainda guardam muitos segredos.
Mas, por sorte, os astrônomos não desistem facilmente.
> Artigos científicos
1.
FALCETA-GONÇALVES, D. et al.
Turbulence and the formation of filaments, loops and shock fronts in NGC 1275.
The Astrophysical Journal Letters.
v.
708 (1), p.
L57-L60.
1 jan.
2010.
2.
FALCETA-GONÇALVES, D. et al.
Precessing jets and X-ray bubbles from NGC 1275 (3C84) in the Perseus galaxy cluster: a view from 3D numerical simulations.
The Astrophysical Journal Letters.
v.
713 (1), p.
L74-L78.
10 abr.
2010.
OS PROJETOS
1.
2.
Modalidade
1.
Projeto Temático
2.
1.
Elisabete de Gouveia Dal Pino – IAG-USP
2.
Diego Falceta-Gonçalves – Unicsul
Investimento
1.
R$ 342.429,60
2.
R$ 110.400,00
Pontos de consenso
Fabrício Marques de Brasília
Os debates da 4a Conferência Nacional da Ciên­cia, Tecnologia e Inovação (CNCTI), que envolveram mais de 4 mil participantes em Brasília entre 26 e 28 de maio, alcançaram uma série de pontos de convergência.
Um segundo ponto de consenso nas palestras e discussões vinculou-se à necessidade de aperfeiçoar os mecanismos de estímulo à inovação nas empresas e de interação entre pesquisadores e o setor privado, que melhoraram nos últimos anos mas têm resultados ainda tímidos.
``É imperiosa a necessidade de que as empresas se dediquem mais a atividades de pesquisa e desenvolvimento, e nosso ambiente econômico não favorece muito essa mudança de cultura'', disse Davidovich.
E, em terceiro lugar, destacou-se a necessidade de promover a exploração sustentável dos biomas brasileiros, como a Amazônia, o Pantanal e o Cerrado, em substituição ao velho modelo que valoriza a extração de madeira e o desmatamento para criação de gado.
Segundo o secretário-geral da conferência, houve ainda um quarto ponto de convergência, embora ainda difuso,em torno da importância de estimular as chamadas ``tecnologias sociais'', que consistem na utilização da capacidade científica do país na solução de problemas do subdesenvolvimento, como a desnutrição e a falta de saneamento, entre outros, trabalhando em parceria com a população necessitada.
``Não há um modelo único a ser seguido, mas existe certo consenso de que as tecnologias sociais poderiam colocar o país na liderança de um tipo de desenvolvimento mais sustentável do que o dos países ricos'', afirmou Davidovich.
As principais conclusões da conferência serão compiladas num documento, o Livro azul de Ciência, Tecnologia e Inovação, que será divulgado antes das eleições presidenciais de outubro.
A ideia é que se torne um texto de referência para políticas de Estado nos próximos 10 anos, sinalizando aos próximos governantes o pensamento da comunidade científica.
Artigos com as propostas apresentadas em cada uma das mesas-redondas e plenárias da conferência serão escritos pelos respectivos relatores e publicados numa edição da revista Parcerias Estratégicas, do Centro de Gestão e Estudos Estratégicos (CGEE), organizador da conferência.
Os avanços obtidos nos últimos anos, como a regularidade no financiamento à pesquisa, o crescimento vigoroso da produção científica e a preocupação ascendente das empresas com a inovação, pontuaram as discussões da conferência, mas algumas perguntas provocativas ajudaram a relativizar o otimismo: a ciência brasileira terá fôlego para dar nos próximos anos um salto que a leve a um patamar de país desenvolvido?
O que falta para o Brasil ganhar um Prêmio Nobel científico?
Quanto tempo levará para reverter a cultura ainda avessa à inovação da maioria das empresas brasileiras?
O matemático Jacob Palis, presidente da Academia Brasileira de Ciências (ABC), disse que um dos grandes desafios para garantir o salto será multiplicar por três, até 2020, o contingente de pessoal envolvido com ciência, de técnicos de laboratório a doutores.
``Temos que acelerar esse processo sem perder qualidade.
Isso exigirá um esforço muito grande da comunidade científica e empresarial.
Será preciso aumentar os investimentos em ciência para atingir, em 10 anos, um patamar de cerca de 2% do PIB'', afirmou Palis, que, otimista, disse que a conquista de um Nobel é questão de tempo.
``Estou disposto a apostar que isso vai acontecer'', afirmou.
O físico Carlos Aragão, presidente do Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), propôs rever conceitos arraigados na prática das universidades brasileiras, como a especialização precoce dos estudantes de graduação.
``É preciso investir em novos recursos pedagógicos, que atualizem as grades curriculares ultrapassadas e motivem os estudantes a se envolver com pesquisa.
É preciso dar menos aulas e estimular mais os alunos a utilizarem seu tempo para efetivamente estudar'', afirmou Aragão, que também sugeriu uma revisão da organização universitária em departamentos.
``Essa compartimentalização atrapalha a pesquisa multidisciplinar'', afirmou.
A necessidade de investir nos núcleos de excelência acadêmicos para superar gargalos foi enfatizada em apresentações como a de Eduardo Krieger, pesquisador do Instituto do Coração (InCor) e membro do Conselho Superior da FAPESP.
O diretor científico da FAPESP, Carlos Henrique de Brito Cruz, disse que o Brasil tem estado, desde o início da década de 1990, entre os quatro países com maior crescimento em número de artigos científicos publicados.
Em termos qualitativos, também houve progressos importantes, com artigos de pesquisadores brasileiros tendo cada vez mais destaque em revistas internacionais.
``A ciência nacional tem experimentado uma ascensão vigorosa em quantidade e qualidade.
Um dos nossos desafios, nesse contexto, é a questão do impacto dessa ciência produzida no Brasil.
A evolução do número de citações é crescente, mas ainda está abaixo da média mundial'', destacou.
Outro desafio, segundo Brito Cruz, é retomar o aumento na taxa de crescimento da formação de doutores.
Até 2003, o número de doutores formados crescia cerca de 18% anualmente.
Desde então, passou a crescer a aproximadamente 5% ao ano.
``Os números mostram que existe alguma restrição importante operando no sistema brasileiro, `puxando o freio de mão' da formação de doutores.
É preciso multiplicar por três o número de pesquisadores para o Brasil atingir patamares semelhantes ao da Espanha, por exemplo'', afirmou.
Brito Cruz defendeu uma abordagem mais ampla para nortear a pesquisa no país.
``Vivemos um momento utilitarista, segundo o qual a ciência precisa ajudar as empresas a inovar, curar doenças ou combater a pobreza.
Isso é importante, mas também é importante fortalecer a ciência que faz a humanidade mais sábia'', disse.
Outro ponto destacado pelo diretor científico da FAPESP foi a necessidade de melhorar a qualidade da pesquisa brasileira e citou iniciativas da Fundação, como a dos Centros de Pesquisa, Inovação e Difusão (Cepids), com financiamento de grupos de excelência por um horizonte de 10 anos.
``Projetos ousados podem precisar de mais tempo para dar resultados.
Muitos desses Cepids estão abordando temas de pesquisa que já não têm relação estreita com os objetivos iniciais.
Só puderam ousar porque tiveram fôlego de longo prazo'', disse Brito Cruz.
Redes - A importância de ampliar e dar mais qualidade aos programas de pós-graduação foi destacada em vários momentos do evento.
Numa sessão que compilou as recomendações de diversas conferências regionais preparatórias, os representantes das regiões Centro-Oeste e Nordeste bateram nesta tecla: é preciso criar novos programas, capazes de formar mais pesquisadores, além de conectar os programas já existentes com os de outras regiões do país por meio da formação de redes.
``Seria interessante dar periodicidade anual para iniciativas do CNPq como o edital casadinho, que conecta programas de pós-graduação consolidados com outros ainda em consolidação'', disse Janesmar Cavalcanti, secretária de Ciência, Tecnologia e Inovação de Alagoas.
Foram apontados diversos caminhos para estimular a capacidade de inovar nas empresas brasileiras.
Os relatos trazidos por representantes de conferências regionais sugeriram a criação de leis estaduais e municipais de inovação, com a integração desses esforços com os do governo federal para estimular as empresas a usar os benefícios.
O gerente executivo do Centro de Pesquisas e Desenvolvimento da Petrobras, Carlos Tadeu Fraga, relatou a estratégia da gigante petrolífera de atrair para o Brasil centros de pesquisa e desenvolvimento de empresas multinacionais interessadas em aproveitar as oportunidades ligadas à exploração do petróleo na camada pré-sal.
Carlos Américo Pacheco, professor do Instituto de Economia da Universidade Estadual de Campinas (Unicamp), propôs a criação de plataformas setoriais de inovação, argumentando que o problema exige um mo­nitoramento mais preciso do que o atual.
Segundo ele, é impraticável seguir apenas metas gerais de inovação, pois a informação sobre o cumprimento das metas demora dois anos para ser aferida, quando já é tarde para corrigir rumos.
Glauco Arbix, professor da Faculdade de Filosofia, Letras e Ciências Humanas (FFLCH) da Universidade de São Paulo (USP), defendeu a criação de uma agência nacional de inovação com peso, recursos e capacidade de patrocinar e articular a interação entre programas, instituições e políticas de ciência, tecnologia e inovação.
``E essa agência não deve ser ligada ao Ministério da Ciência e Tecnologia, mas à própria Presidência da República, para sinalizar que se trata de uma ideia prioritária.
O Brasil é muito grande para ter programas pequenos.
Precisamos hierarquizar e selecionar melhor nossas prioridades'', disse.
Para Arbix, há uma crescente maturidade no debate sobre CT&I no Brasil.
``A maneira como as instituições empresariais tentam tratar a tecnologia tem, hoje, uma perspectiva diferente da que víamos há alguns anos.
Temos que aproveitar este momento para dar um salto'', disse.
Floresta em pé - A inovação também tem um papel crucial na construção de um projeto de desenvolvimento sustentável para a Amazônia, disse Bertha Becker, professora emérita da Universidade Federal do Rio de Janeiro (UFRJ).
Segundo ela, a região tem hoje duas propostas de projetos de desenvolvimento sustentável.
``Um desses projetos, que está associado às mudanças climáticas, tem predominado.
Esse projeto defende a preservação da floresta em pé, financiando a renúncia ao desmatamento.
Questiono fortemente esse projeto, pois ele mantém a floresta improdutiva.
É basicamente um projeto de compensação para países desenvolvidos que poderão continuar sendo os maiores emissores'', disse.
O outro projeto, segundo Bertha, entende o desenvolvimento sustentável como um novo padrão de desenvolvimento baseado na ciência, na tecnologia e na inovação.
``O desafio, nesse caso, é utilizar os recursos naturais sem destruí--los, gerando emprego e renda para os milhões de habitantes da região.
Só conseguiremos isso com políticas públicas e imensos investimentos em ciência e inovação'', destacou.
No mesmo evento, o ministro da Educação, Fernando Haddad, sugeriu ao colega Sergio Rezende, titular da Ciência e Tecnologia, que as conclusões da Conferência Nacional de Educação, ocorrida entre 28 de março e 1o de abril, sejam encaminhadas ao Congresso Nacional em conjunto com os resultados da CNCTI, criando uma política conjunta para os próximos 10 anos.
Política de C & T > Divulgação
Parceria entre cientistas e jornalistas em prol da cultura científica ainda está distante
Mariluce Moura, de Madri* e Brasília
Ainda que jornalistas sejam na origem generalistas por definição, hoje estão se acumulando as evidências de que os profissionais do jornalismo científico em toda parte – e não apenas nos paí­ses de tradição anglo-saxônica – investem mais e mais na estratégia do aperfeiçoamento contínuo para exercer seu ofício com o necessário rigor, espírito crítico e, claro, um grau de conhecimento indispensável do campo que é objeto de suas narrativas.
Nessa busca valem tanto os caminhos tradicionais da pós­-graduação que permitem refletir e investigar com apoio teórico e mais profundamente sua própria prática quanto as oficinas e workshops de caráter mais pragmático que se propõem, por exemplo, a ampliar em curto prazo a competência dos jornalistas no manejo das bases de dados de produção científica, na separação do joio e do trigo – diga-se, ciência e pseudociência – dentro da vastidão da web e nas vias de articulação possíveis e eficazes entre redes sociais e jornalismo, entre outros temas.
Vale dizer que essas recomendações consensuais foram construídas a despeito de toda a diferença entre as experiências de jornalismo científico e cultural apresentadas e mesmo das divergências conceituais profundas que se explicitaram.
Assim, se para alguns jornalistas a internet e a democratização da produção de conteúdos via web representam uma ameaça à própria existência de sua profissão, para outros, como o diretor adjunto do respeitado jornal espanhol El País, Gumersindo Lafuente, constituem um belo desafio à quase reinvenção do jornalista.
“Nossa narrativa foi sempre conectada com a realidade e hoje a realidade está nas ruas e está na rede.
Como jornalistas, temos que contar o que se passa também na rede”, disse ele.
Observou que não estamos mais em tempo de esperar que as pessoas vão em busca dos meios de comunicação, e sim em tempo “de irmos com nossas histórias aos lugares em que se está falando dos temas que tratamos na internet”.
E ainda apostou que, como num ambiente darwiniano, “as plataformas da internet que tenham qualidade, sejam blogs ou twitters, se converterão em marcas, enquanto os meios que já são marcas só vão sobreviver se conservarem sua qualidade”.
A propósito, Milagros, ao participar no dia anterior da mesa-redonda sobre “divulgação do conhecimento científico e as indústrias da ciência” (que incluiu a apresentação sobre a experiência de Pesquisa FAPESP), observara que “a notícia científica tem um grande valor quando bem elaborada, porque gera opinião e conhecimento, mas é a mais arriscada quando malfeita e tendenciosa porque pode provocar danos sociais pelos quais vamos todos pagar”.
Em sua visão as portas do jornalismo estão cada dia mais abertas para a pseudociência, o que exige, em especial na informação digital, contenção e comprovação.
No meio das discussões pairava alguma coisa da fala do professor José Manuel Sánchez Ron, catedrático de história da ciência na Universidade Autônoma de Madri, na conferência inaugural do encontro.
“Cultura e ciência são parte da vida intelectual, mas entre elas existe uma mútua incompreensão, hostilidade e antipatia.”
Os meios de comunicação, além de informar, em sua visão, devem educar ao tratar da ciência – com o que dificilmente algum jornalista concordará em termos estritos.
Silêncio e ruídos – Se no front dos jornalistas e dos cursos de comunicação há visível preocupação com a qualidade do jornalismo científico, há indícios de que dentro do sistema nacional de ciência e tecnologia a ideia de parceria com os meios de comunicação para difundir a cultura científica na sociedade, que parecia vicejar no começo da década, experimenta hoje retrocesso.
Assim, na IV Conferência Nacional de Ciência, Tecnologia e Inovação, realizada de 26 a 28 de maio em Brasília (ver reportagem na página 26), evento em que se procurou ressaltar ao máximo as parcerias entre a comunidade científica, o Estado, os empresários e os chamados setores sociais, para o desenvolvimento de uma verdadeira sociedade do conhecimento no país, o papel da mídia foi ignorado, mesmo quando se falava em popularização da ciência.
Entre todos os debates, reservaram-se apenas 15 minutos à fala de um jornalista, aliás, uma jornalista, a presidente da Associação Brasileira de Jornalismo Científico (ABJC), Cilene Victor, dentro da sessão “Construção da cultura científica”.
Vale lembrar que na II Conferência Nacional, em 2001, sob o comando do ministro Ronaldo Sardenberg e organização do professor Cylon Gonçalves, foram várias as mesas que debateram a questão da comunicação pública da ciência com mediação do jornalismo.
Dessa forma, parece voltar à cena, de certa maneira, uma velha visão meramente instrumental do jornalismo ante a ciência, o primeiro submetido à segunda, em vez de uma visão mais contemporânea de parceria para a difusão social do conhecimento.
* A jornalista viajou a convite da Organização dos Estados Ibero-americanos (OEI).
Política de C & T > Ambiente
Democracia na selva
Possibilidade de conciliar exploração e preservação da floresta aproxima governo e empresários, mas enfrenta resistências
Carlos Fioravanti, de Itaituba*
O diálogo entre grupos antes distantes floresce no interior do Pará.
No final da tarde do dia 10 de maio, em uma das salas da prefeitura de Itaituba, sudoeste do Pará, sete integrantes do alto escalão do Serviço Florestal Brasileiro, órgão ligado ao Ministério do Meio Ambiente, se reuniram com oito empresários do setor madeireiro para conciliar seus interesses em torno de uma nova forma de exploração econômica da Amazônia – a concessão florestal, por meio da qual o governo federal seleciona empresas que possam explorar áreas previamente definidas de florestas públicas por um período de 40 anos de modo a causar o menor impacto ambiental possível, diferentemente da atual abordagem de eliminação total da vegetação nativa.
A cordialidade imperou ao longo da conversa, mas as palavras soavam cautelosas e os olhares expressavam a desconfiança recíproca.
Ouvir os interessados ou quem possa ser atingido pelas decisões faz parte dessa nova abordagem de uso das terras públicas.
Com base na Lei de Gestão de Florestas Públicas, aprovada em 2006, o Serviço Florestal selecionou em 2008 três empresas para explorar 96 mil hectares da Floresta Nacional do Jamari, em Rondônia, por meio do primeiro edital de licitação para concessão de florestas públicas.
A equipe do Serviço Florestal trabalha agora na análise das propostas apresentadas no segundo edital, para exploração de 140 mil hectares da Floresta Nacional de Saracá-Taquera, no Pará, e na versão final do terceiro edital, para concessão de 210 mil hectares, o equivalente a 1,4 vez a área do município de São Paulo, da Floresta Nacional de Amana, nos municípios de Itaituba e Jacareacanga, no Pará.
“Dizem que é pouco, mas é só o começo”, disse Antonio Carlos Hummel, diretor-geral do Serviço Florestal.
Essa forma de exploração, chamada de manejo florestal sustentável, poderia ser adotada em 20 milhões dos 239 milhões de hectares de florestas públicas – a área total de florestas no Brasil, 524 milhões de hectares, equivale a 61% do território nacional.
Em julho a exploração de madeira deve começar nas áreas do primeiro edital, as empresas selecionadas do segundo edital devem ser anunciadas, o terceiro edital, em Itaituba e Jacareacanga, lançado e o calendário de reuniões para o edital seguinte, também no Pará, apresentado publicamente.
Por meio das propostas aprovadas em cada edital, as empresas podem retirar de cinco a seis árvores por hectare a cada 30 anos, quatro vezes menos que a perda causada por razões naturais e muito menos que o desmatamento, que suprime toda a vegetação.
As empresas podem também retirar látex, cipós, óleos, frutos e sementes e criar atividades turísticas nas áreas concedidas, de acordo com planos previamente aprovados.
“Não podemos colher mais do que a floresta pode produzir”, diz Roberto Waack, presidente da Amata, uma das três empresas selecionadas para explorar as áreas licitadas em Rondônia.
As empresas que vencerem os editais terão de se comprometer a contratar na própria localidade pelo menos 80% dos trabalhadores de que precisar e a pagar para o Serviço Florestal um preço mínimo por metro cúbico de madeira, proporcional ao valor comercial de cada espécie – entre as de maior valor estão ipê, cedro-rosa, jatobá e maçaranduba.
Na conversa do dia 10, os madeireiros reclamaram do preço mínimo, que consideraram muito alto.
No dia seguinte, ao lado de representantes dos trabalhadores, movimentos sociais e comunidades locais, os madeireiros apresentaram essas reivindicações, com uma argumentação mais detalhada, na audiência pública que reuniu cerca de 250 pessoas no ginásio de esportes da cidade.
“A concessão de florestas públicas é uma saída”, reconheceu Osvaldo Romanholi, presidente do sindicato das indústrias madeireiras do sudeste do Pará, “mas não no curto prazo”.
Luta contra a ilegalidade
Um ano depois de os diretores e gerentes do Serviço Florestal terem aterrissado em Itaituba e apresentado a nova abordagem de exploração madeireira, então sob uma resistência muito mais intensa, a concessão florestal soa como inevitável, já que o espaço para as empresas atuarem na ilegalidade parece bem menor hoje do que há duas ou três décadas.
“Queremos reduzir a ilegalidade da exploração madeireira e o desmatamento”, argumentou Hummel.
Nas reuniões prévias e na audiência pública, ele disse que faria o possível para atender às reivindicações.
“Temos amarras legais que não nos permitem fazer tudo que gostaríamos”, preveniu Marcelo Arguelles, gerente de concessões do Serviço Florestal, em uma das conversas com os madeireiros.
“Ainda vamos brigar muito, também temos advogados”, antecipou um empresário de Jacareacanga, um dos municípios mais pobres do Pará, onde correu outra audiência pública três dias depois.
No banco de trás de um bimotor Cessna, em um sobrevoo da floresta com jornalistas, Luiz Cesar Cunha Lima, coordenador de editais do Serviço Florestal, olhou para as áreas a serem licitadas e comentou: “Vejam, é uma área ótima para manejo florestal sustentável.
É um maciço florestal, não tem rios nem morros”.
Seiscentos metros abaixo, a floresta se estendia a perder de vista.
Na audiência pública, um madeireiro lembrou que por ali existem morros, sim, e que não há estradas até as áreas a serem exploradas, a cerca de 200 quilômetros da cidade – vista do alto, a principal estrada da região, a Transamazônica, é um fio de terra que corta a floresta e pode não resistir ao peso de carretas carregadas de toras de madeira.
A perspectiva de conciliar interesses é uma novidade no oeste do Pará, marcado pelas atividades econômicas ilegais e pelos conflitos de terra.
“Até quatro anos atrás ninguém sabia o que era estar dentro da lei”, conta Romanholi, que veio de Mato Grosso há 11 anos.
As coisas começaram a mudar a partir de 2003, com a retomada da construção da rodovia BR-163, entre Cuiabá, em Mato Grosso, e Santarém, no Pará, ainda hoje só parcialmente asfaltada.
Três anos depois, a criação do Distrito Florestal Sustentável BR-163 lançou o desafio de explorar sem destruir 19 milhões de hectares de floresta nativa em 10 municípios próximos à rodovia.
Das 254 empresas antes em atividade na área do Distrito Florestal Sustentável restaram 39.
“Hummel era chamado de carrasco dos madeireiros”, resgata Romanholi.
“O acesso a terras públicas era muito fácil”, rebate Hummel.
A ordem começou a se impor, mas os ressentimentos persistem.
“O governo criou uma reserva em cima de minha propriedade”, acusa Walmir Climaco, prefeito de Itaituba.
Ele havia assumido seu posto na prefeitura duas semanas antes (o prefeito anterior foi cassado por ter distribuído 5 mil cestas básicas a pessoas não cadastradas), chegou 45 minutos atrasado à audiência pública e não escondia sua descon­fiança: “No passado a opinião pública não teve muito valor.
O governo federal já esteve aqui outras vezes, ouviu muita gente e depois fez o que quis”.
O próprio prefeito sentiu os efeitos da legalização da exploração madeireira na região.
Dos seus 250 empregados antes contratados para explorar uma área de 3 mil hectares de florestas, mantém apenas três vigias.
“Está tudo 100% parado, porque não tinha regularização”, diz.
Climaco é dono também de 5 mil hectares de garimpo e de 17 fazendas com 100 mil cabeças de gado.
“Até 1988 o desmatamento era autorizado”, lembrou, em uma das conversas que correram ao longo da audiência pública.
Cearense de 49 anos, ele chegou a Itaituba há 32 anos, “nos tempos do ministro Mário Andreazza”, disse, referindo-se à época da ditadura.
“O Estado está começando a chegar ao interior da Amazônia, em todos os sentidos”, observa Fernando Ludke, diretor regional do Serviço Florestal.
Estabelecida como município em 1856, Itaituba abriga 130 mil moradores já indiferentes ao clima quente e úmido.
Nos finais de tarde a rapaziada se instala nos bancos da orla, abre os laptops e se liga à rede pública de acesso à internet.
Enquanto isso, o esgoto sem tratamento corre para o rio Tapajós.
À noite é fácil ver ratos e cachorros revirando o lixo abandonado nas ruas.
Nessa região já correu muito ouro – muito mais do que os atuais 100 quilogramas (kg) por mês, segundo José Antunes, presidente de Associação de Mineração do Ouro do Tapajós, ou 300 kg, segundo o prefeito.
Em um canto do aeroporto de Itaituba, um desenho feito a partir de uma foto retrata os tempos áureos: um avião que ao aterrissar se sobrepôs parcialmente a outro em um momento de tráfego intenso no lugar que tem a fama de ter sido o aeroporto de aviões pequenos mais movimentado no Brasil.
“Tinha muito ouro, muita mulher, muita cachaça.
Hoje está civilizado.
Perdeu a graça”, diz um ex-garimpeiro que observa a audiência a distância e, em vez de contar o nome, deixa escapar um sorriso maroto de quem relembra os velhos tempos.
Depois, novamente sério, acrescenta: “Esta região é uma ferida crônica na selva”.
Um ou outro morador conta que ainda circulam uns poucos dos antes frequentes pistoleiros que matavam por causa de ouro, terra ou mulheres.
O número de empregos a serem realmente criados e a rentabilidade da floresta estão sujeitos a ajustes, à medida que as árvores começarem a sair da mata rumo às serrarias.
Só o tempo dirá também se tem sentido um dos temores dos moradores – que poderosas multinacionais vençam os editais e se sobreponham às empresas locais – e se a concessão de florestas funcionará efetivamente como estratégia de ordenamento territorial da Amazônia.
Ao menos a transparência com que os editais estão correndo, com cada passo relatado na internet, impressiona.
Do mesmo modo, os riscos à integridade da floresta parecem mínimos, de acordo com estudos iniciados há cerca de 60 anos na Amazônia.
Em um experimento feito na Floresta Nacional do Tapajós, em Santarém, no Pará, as árvores com diâmetro acima de 45 centímetros de uma área total de 64 hectares foram inventariadas em 1975 e colhidas em 1979 em uma proporção de volume por hectare equivalente a mais que o dobro da permitida atualmente.
O mesmo trecho de floresta foi reavaliado em 2009 – portanto, 30 anos depois, o mesmo intervalo entre colheitas estabelecido pela legislação atual.
“A floresta mostrou uma capacidade de recuperação a ponto de permitir outra colheita, dentro dos limites atuais de intensidade de corte”, relata José Natalino Macedo Silva, diretor do Serviço Florestal
Contrato de longo prazo
“Após a retirada das árvores, a diversidade de espécies diminui momentanea­mente, mas depois se recupera”, diz.
Segundo ele, depois de 30 anos a extração de madeira na Floresta Nacional do Tapajós ampliou – em vez de diminuir, como muitos biólogos temiam – a diversidade de espécies, porque trouxe luz e espaço para outras espécies germinarem e crescerem.
“Novas espécies entram e saem constantemente, porque a floresta é um ambiente dinâmico, sujeito a diversos tipos e intensidades de perturbações, como furacões, deslizamentos de terra ou clareiras que surgem quando as árvores morrem e caem”, comenta Natalino.
“Com o manejo florestal, o que o homem faz é controlar a intensidade das intervenções, de modo a minimizá-­-las e possibilitar colheitas sustentáveis por tempo indefinido.”
Segundo ele, os contratos de concessão limitam o impacto da construção da infraestrutura (estradas, pátios de estocagem de toras e as chamadas trilhas de arraste) a 8% da área da floresta.
“A legislação atual é cautelosa quanto aos impactos ambientais do manejo porque exige que as empresas florestais deixem pelo menos três árvores de cada espécie em cada 100 hectares e 10% das árvores em tamanho de corte para garantir continuidade das espécies.”
As regras atuais para exploração de florestas nativas implicam a divisão da área a ser explorada em 30 partes.
A cada ano é permitido aproveitar apenas 1/30 e as empresas têm de manter uma reserva de 5% de cada tipo florestal em cada área.
“Hoje o Ibama utiliza 140 verificadores de boas práticas de manejo”, diz Natalino.
O plano de trabalho, a ser aprovado pelo governo federal, apoia-se em um inventário com a identificação botânica – autenticada por um herbário oficial – das árvores de cada área a ser explorada.
Na sede de Amata, em São Paulo, no 17o andar de um prédio próximo ao rio Pinheiros, Roberto Waack conta que sua equipe identificou a espécie, a altura e o diâmetro de cerca de 27 mil árvores do primeiro lote que deve começar a explorar depois de o Ibama aprovar seu plano de que árvores cortar.
Segundo ele, mesmo com todo esse trabalho prévio, essa operação compensa economicamente porque o custo de explorar uma floresta já formada é bem menor do que o de uma de eucalipto ou pinus que precisa ser plantada e só produz madeira após pelo menos sete anos.
Além disso, como o espaço das madeiras de origem ilegal está se reduzindo, “a demanda por madeira de origem certificada tem sido maior do que a oferta”, diz Waack.
Seu plano é produzir os chamados plainados secos – peças tratadas para uso em pisos e batentes – ainda este ano em uma serraria que está montando em Rondônia.
Em 2011 ele quer começar a usar os rejeitos da exploração da madeira para produzir blocos que lembram ração para cães e são usados como combustíveis em fornos.
“O manejo tem de estar integrado com a adição de valor aos produtos da floresta”, diz Waack.
“Não entramos na mata pensando em tirar tudo rápido e ir embora.
Estamos sob a proteção de um contrato de 40 anos.”
A visão de longo prazo faz diferença.
Uma das sócias da Amata é a designer Etel Carmona, que começou a trabalhar há 20 anos com madeiras tropicais e hoje vende no Brasil e na Europa móveis e objetos como um vaso exclusivo de madeira pelo equivalente a quase R$ 5 mil.
Carlos Fioravanti
Especialistas do Brasil e de outros países reunidos em maio em São Paulo concluíram que a produção de biocombustíveis -- em especial o etanol -- pode se expandir sem disputar espaço com a produção de alimentos e causando menos impacto ambiental se houver mais pesquisa científica e tecnológica e mais interação com as políticas públicas de desenvolvimento econômico e social.
``Os formuladores de políticas públicas estão confusos, diante de tantas incertezas sobre a viabilidade de um futuro sustentável'', comentou Lee Lyndt, pesquisador do Dartmouth College, Estados Unidos, em uma das apresentações do workshop Scientific Issues on Ethanol, realizado nos dias 24 e 25 de maio na sede da FAPESP.
Ele e outros palestrantes ressaltaram os impactos ambientais negativos do atual modelo de produção de energia no mundo, fundamentado em combustíveis não renováveis, principalmente petróleo, carvão e gás natural.
``Nosso conforto depende de combustíveis fósseis'', disse José Goldemberg, da Universidade de São Paulo.
Ocorre que, segundo ele, esse modelo energético não só está sujeito ao esgotamento, à medida que as reservas de petróleo se exaurem, mas também é socialmente injusto, já que os habitantes dos países europeus consomem o equivalente a seis toneladas de petróleo por ano e os da África, 10 vezes menos.
``O uso de fontes renováveis modernas, sonho dos ambientalistas, está crescendo, mas ainda tem um caminho longo para ser adotado mais amplamente.
O futuro pertence às energias renováveis, definitivamente, mas daqui a 20 ou 30 anos.''
Goldemberg foi um dos autores de um relatório solicitado há dois anos pelo Conselho InterAcademias a 15 academias de ciência, o Lighting the way: toward a sustainable energy future.
Recém-publicado pela FAPESP (Um futuro com energia sustentável: iluminando o caminho, 300 páginas), esse documento ressalta o papel dos governos para apoiar investimentos de longo prazo em infraestrutura energética e pesquisas que ajudem a disseminar as fontes de energia renovável, incluindo os biocombustíveis.
``A expansão da produção de biocombustíveis no Brasil e nos Estados Unidos levantou uma séria controvérsia sobre a incompatibilidade entre alimentos e combustíveis'', lembrou Goldemberg.
Ao longo dos dois dias de debates promovidos pela FAPESP, Academia Brasileira de Ciências (ABC) e o InterAcademy Panel (IAP), esse conflito se desfez e a limitação de terras deixou de ser considerada um obstáculo para a expansão da produção de etanol.
Hipoteticamente, dobrar a produtividade da pecuária brasileira -- de um para dois bois por hectare -- poderia acrescentar 100 milhões de hectares aos atuais 4 milhões de hectares de cana-de-açúcar, suprindo assim dois terços da demanda mundial de etanol.
Mudanças à vista - Além disso, 1 bilhão de acres poderiam ser usados para agricultura no mundo.
``O Brasil aproveita apenas 1% da área que poderia ser aproveitada para agricultura'', afirmou Carlos Henrique de Brito Cruz, diretor científico da FAPESP.
Vários palestrantes observaram que o melhor uso das terras poderia ampliar a produção de etanol e, ao mesmo tempo, atender à demanda crescente por alimentos e reduzir a pobreza no mundo.
Patricia Osseweijer, pesquisadora do Delft University of Technology, da Holanda, contou que o atual portfólio de fontes de energia na Europa não é ambientalmente seguro nem sustentável, mas há sérias limitações para a implantação de fontes alterna­tivas.
Segundo ela, mesmo que os países europeus usassem 40 milhões de hectares para a produção de biocombustíveis, apenas um terço da de­manda seria atendido.
``Encontrar soluções duráveis, biodegradáveis, ambientalmente amigáveis e economicamente viáveis é muito difícil'', reconheceu.
``Precisamos aumentar a participação pública e melhorar a qualidade da comunicação.
Os debates ainda carecem de clareza e refletem apenas um dos lados.''
Horward Alper, da Universidade de Ottawa, Canadá, reiterou: ``Comunicar-se de um modo claro e conciso é absolutamente crucial.
Você tem de ser entendido por sua filha de 16 anos''.
Mudanças profundas em outros hábitos parecem ser indispensáveis na busca de um planeta com menos poluição.
Como atualmente o setor de transportes consome um terço da energia produzida no mundo, Cylon Gonçalves, professor emérito da Universidade Estadual de Campinas (Unicamp) e coor­denador adjunto da FAPESP, comentou: ``Só uma radical transformação dos meios de transporte e das necessidades da humanidade nos levará a uma sustentabilidade.
Há limites científicos e técnicos para um crescimento contínuo da demanda''.
Algumas mudanças poderiam ser imediatas.
``Se países em desenvolvimento como a China e a Índia continuassem usando carvão, mas com tecnologia dos Estados Unidos ou do Japão, ganhariam em eficiência energética e a emissão de gases do efeito estufa cairia um terço'', sugeriu Goldemberg.
Paciente na ponta da linha
Marcos Pivetta
Desde fevereiro deste ano alguns agentes de um posto de saúde localizado na periferia do município de São Paulo saem a campo para coletar informações sobre a população local carregando um potente aliado de bolso: um celular inteligente, daqueles que se conectam à internet pela rede de dados 3G, possuem um tecladinho para escrever, têm GPS e são acionados por comandos numa tela sensível ao toque.
Com o aparelhinho em mãos, as equipes de saúde da família da Unidade Básica de Saúde (UBS) Paulo VI, localizada nas proximidades da rodovia Raposo Tavares, nos confins da Zona Oeste paulistana, podem deixar de lado caneta e papel e registrar diretamente no smartphone as informações de cada casa visitada e de seus habitantes.
Se não houver nome formal na rua onde reside o morador, situação que não é impossível de ocorrer, não há problema.
O GPS do celular sempre registra as coordenadas geográficas de cada ficha criada pelos agentes de saúde.
Terminada a visita, a equipe da UBS salva a ficha e, na própria residência do morador, a envia com a ajuda do telefoninho ao banco de dados do projeto.
Em segundos, o perfil médico de uma família da Paulo IV está num computador da FMUSP.
O uso do celular inteligente como forma de abastecer o embrião de um futuro prontuário on-line faz parte de uma série de iniciativas destinadas a reorganizar e humanizar o atendimento do Sistema Único de Saúde (SUS) numa parte da Zona Oeste da capital paulista, na microrregião que inclui os bairros do Butantã e do Jaguaré, onde moram aproximadamente 420 mil pessoas.
Esse é o principal objetivo do Projeto Região Oeste, que também desenvolve ações de pesquisa científica e de ensino de medicina.
Em outubro de 2008 a FMUSP assinou um contrato de gestão com a Secretaria Municipal da Saúde da cidade de São Paulo e passou a administrar, por meio do projeto, a estrutura primária de postos de saúde e de ambulatórios e também os pronto-socorros existentes nesses dois bairros (ver reportagem na edição 164 de Pesquisa FAPESP).
Nessa área da cidade, que começa a virar um laboratório de novas práticas do SUS, a implantação do projeto é gradual.
Por ora, cinco das 14 UBS da região já estão sob o comando da equipe do projeto.
Na Paulo VI, os pesquisadores da FMUSP decidiram atacar uma das fraquezas do sistema público de saúde: a baixa qualidade da informação médica a respeito dos pacientes que usam o SUS.
``Uma base de dados eficiente vai fazer o sistema integrado de saúde fruir melhor'', afirma Sandra Grisi, presidente do conselho diretor do Projeto Região Oeste.
``Assim como o paciente, a informação também tem de circular no sistema.''
Segundo Alexandra Brentani, diretora executiva do projeto, há atualmente uma grande escassez de dados sobre a população que mora na área de atuação de uma UBS ou de um posto de saúde na cidade de São Paulo.
Quando existem equipes de saúde da família que visitam regularmente as casas da região, toda a informação coletada é anotada numa ficha de papel.
O problema é que às vezes essa informação se perde pelo caminho -- não chega a ser digitalizada -- e nem entra em sistemas informatizados.
``Mesmo quando os dados são inseridos no Siab [Sistema de Informação de Atenção Básica, mantido pelo Ministério da Saúde], eles não se tornam perenes'', comenta a administradora da FMUSP especializada na gestão de recursos de saúde.
``Depois de um mês eles são apagados.''
Para resolver esse entrave, a equipe do Região Oeste se pôs a pensar numa forma alternativa de os próprios agentes comunitários abastecerem diretamente, sem intermediários, o banco de dados médicos durante suas idas a campo.
Fornecer um laptop para os agentes seria uma possibilidade, mas o risco de os micros serem roubados na rua seria grande.
Sobraram os smartphones, mais discretos, mas que dão conta do serviço.
``As pessoas já sabem usar os celulares e, com um mínimo de treinamento, conseguem preencher a ficha eletrônica'', diz Marco Antonio Gutierrez, coordenador de informática do projeto.
Salvamento automático - O passo seguinte foi definir que tipo de aparelho seria o mais adequado para ser testado no trabalho das equipes de saúde da família.
Os pesquisadores optaram por celulares que rodam o sistema operacional Android, desenvolvido pelo Google, e criaram um software de coleta de dados, o GeoHealth, que funciona nessa plataforma.
O acesso à programação que faz o Android funcionar é totalmente aberta e gratuita, característica que facilita o trabalho dos desenvolvedores de aplicativos.
Isso faz com que o GeoHealth se integre facilmente ao celular e permite um uso amigável.
Com exceção do nome das pessoas, não é preciso digitar quase nada no GeoHealth.
Escrever nos diminutos teclados dos smartphones não é tarefa cômoda.
Por isso o pessoal do Região Oeste criou uma ficha em que o preenchimento se dá apenas por toques na tela do aparelho.
Praticamente todas as informações sobre a moradia e o histórico de saúde de seus habitantes são inseridas dessa forma.
Nos testes na UBS Paulo VI, os agentes de saúde estão usando cinco aparelhos (três da Motorola e dois da LG, empresas que fizeram parcerias com o projeto) e transmitindo os dados pela rede 3G da Tim, que também apoia a iniciativa.
``Se na área em que o agente está não há sinal da rede, o GeoHealth salva automaticamente os dados na memória do celular'', diz João Henrique Gonçalves de Sá, analista de sistemas do Região Oeste.
``Assim que o aparelho encontra o sinal, a ficha salva é automaticamente transmitida para nosso banco de dados.''
Com a ajuda dos celulares, que são bloqueados para fazer ligações telefônicas, os registros de cerca de 150 famílias que habitam na área de atuação da UBS Paulo VI, algo como 700 pessoas, já foram inseridos no sistema criado pela FMUSP.
Como todos os dados são georrefenciados, é possível visualizar no sistema de mapas do Google a situação de saúde dos moradores de uma única casa e também o quadro médico mais geral de todas as residências da região.
Essa ferramenta será de grande valia para a elaboração de estudos epidemiológicos no futuro, sobretudo quando o banco de dados do projeto tomar corpo e passar a incluir informações de moradores atendidos por outras UBS do Butantã e do Jaguaré.
Quando alguém quiser saber onde estão, por exemplo, localizados os casos de grávidas com dengue num bairro, bastará fazer uma pesquisa no banco de dados para encontrar a resposta.
``Tivemos também a preocupação de fazer um sistema que pode ser totalmente integrado ao banco de dados do Ministério da Saúde, inclusive à ficha médica adotada no Siab'', comenta Alexandra.
Embora um smartphone ainda não seja um item barato a ser incluí­do entre os equipamentos fornecidos pelo SUS a seus agentes, os pesquisadores da FMUSP acreditam que, a longo prazo, eles se pagam e podem ser a base de um sistema mais eficiente de coleta de dados médicos.
Ciência > Capa
Fora de controle
Inflamação desencadeada pela sepse danifica o coração
Salvador Nogueira
Defender o organismo de si mesmo quando ele lança um ataque desesperado contra suas próprias células é o principal desafio dos médicos nos casos de sepse, infecção generalizada causada por bactéria ou vírus, acompanhada por uma inflamação agressiva contra os órgãos que deveria proteger.
Avaliando a saúde de pacientes com sepse, problema que a cada ano atinge 18 milhões de pessoas no mundo, médicos do Brasil e de outros países observaram que o risco de morrer aumenta muito quando o órgão mais danificado é o coração: a taxa de óbito chega a 80% se o músculo cardíaco é afetado e passa a bombear com menos eficiência sangue rico em oxigênio para o restante do corpo, ante 20% quando não há dano cardíaco.
Agora pesquisadores da Universidade de São Paulo (USP) em Ribeirão Preto deram um passo além.
Analisando o coração de pessoas e animais que morreram com sepse, a equipe coordenada pelo patologista Marcos Rossi e pelo farmacologista Fernando Cunha caracterizou o tipo de dano que a inflamação associada à sepse provoca nas células cardíacas.
Mais importante: encontrou também um caminho promissor para proteger o coração e, assim, ganhar tempo para que o corpo recupere o controle da situação.
O principal avanço do grupo de Ribeirão foi ver o que acontece com as células cardíacas em escala molecular.
Em estudos com animais em laboratório, os pesquisadores descobriram que moléculas de óxido nítrico liberadas na inflamação danificam a parede das células, tornando-as mais permeáveis ao cálcio.
A consequência dessa alteração é uma superdosagem desse elemento químico que leva à morte celular – se a proporção de células afetadas for muito grande, diminui a capacidade do coração de bombear sangue.
Publicado em março de 2010 no periódico científico Shock, esse achado é especial porque sugere formas de frear o processo de desgaste do coração.
É que existem no mercado medicamentos que bloqueiam a absorção do cálcio, usados no controle da pressão arterial e na regulação do ritmo cardíaco.
Atualmente o grupo de Cunha e Rossi avalia, em parceria com pesquisadores do Albert Einstein College of Medicine, em Nova York, se essas drogas ajudam de fato a manter o coração funcionando quando administradas durante um quadro de sepse.
O estudo ainda está em andamento, mas os resultados preliminares são bastante expressivos.
Em um dos experimentos, os pesquisadores administraram compostos que impedem a absorção de cálcio – os chamados bloqueadores dos canais de cálcio – a camundongos que haviam sofrido perfuração nos intestinos e desenvolvido infecção generalizada.
Em seguida, compararam com o que acontecia com um grupo de animais com sepse não tratados e com um grupo de roedores saudáveis.
Os bloqueadores dos canais de cálcio proporcionaram algum grau de sobrevida aos camundongos doentes.
Sem o medicamento, a maioria dos animais com sepse morria em menos de 24 horas.
Quando tratados, porém, todos sobreviveram ao primeiro dia.
“A taxa de morte dos animais com sepse que receberam bloqueador de cálcio foi semelhante à dos camundongos do grupo de controle, que não tinha infecção”, explica Rossi.
“É um resultado que nos deixou entusiasmados.”
Ainda são necessários muitos testes – e possivelmente anos de trabalho – para comprovar se essa estratégia é eficiente e pode ser adotada com segurança no dia a dia dos hospitais.
Mas um fato deixa os pesquisadores otimistas: será mais simples rea­lizar testes com seres humanos, uma vez que os bloqueadores de canais de cálcio já são utilizados para tratar problemas cardíacos.
Rossi lembra, porém, que é prematuro supor que tudo dará certo, pois as circunstâncias a que os animais foram submetidos são bem diferentes das que envolvem os pacientes nos hospitais.
Como patologista, Rossi realizou muitas autópsias em pacientes que morreram com sepse e constatou que quase sempre o coração deles havia passado por mudanças radicais.
“O coração de um paciente com sepse era diferente, meio flácido, o que indicava que em vida havia apresentado problema de funcionamento”, afirma.
A análise do material obtido nas autópsias de fato indicava alterações morfológicas no músculo cardíaco.
Apresentadas na Shock em 2007, essas alterações eram como um retrato do momento final.
A fim de conhecer como iniciam e evoluem os danos cardíacos associados à sepse, os pesquisadores tiveram de recorrer a um modelo experimental do problema – eles escolheram trabalhar com camundongos porque o organismo desses roedores funciona de modo semelhante ao humano.
Por meio de uma incisão no intestino do animal, bactérias do trato digestivo alcançam a cavidade torácica e provocam uma infecção generalizada.
Já de início, os pesquisadores notaram uma modificação importante da estrutura do coração dos animais que desenvolviam sepse: houve uma redução expressiva na quantidade das proteínas responsáveis por manter as células do coração fortemente unidas.
Como resultado, essas células, conhecidas como cardiomiócitos, se desconectavam umas das outras, observou Rossi ao analisar o tecido ao microscópio eletrônico.
Era como se, em nível celular, o músculo cardíaco estivesse sendo desmontado.
Ainda que essa transformação, descrita em 2007 na Critical Care Medicine, ocorresse no nível microscópico, o desmonte produzia consequências facilmente observáveis.
Para o coração bater com regularidade, suas células precisam estar firmemente ligadas entre si, de modo que contraiam ou relaxem em sincronia.
Com as células desconectadas, o ritmo cardíaco tornava-se irregular e o coração rapidamente parava.
O problema estava no exterior, no chamado meio extracelular.
O grupo notou que uma estrutura proteica – o complexo distrofina-glicoproteína (DGC), que serve como ponto de apoio e dá forma às células – parecia se dissolver no coração dos animais vítimas da sepse, revelaram os pesquisadores de Ribeirão em artigo publicado no Laboratory Investigation de abril deste ano.
Se esses danos cardíacos forem de fato provocados pela inflamação associada à sepse, a saída para aumentar a taxa de sobrevivência de quem desenvolve as formas mais graves pode estar no controle da inflamação e dos danos por ela causados.
De acordo com os pesquisadores de Ribeirão, essa seria uma transformação importante na maneira de lidar com o problema, uma vez que, em geral, tenta-se combater apenas os agentes infecciosos com antibióticos e antivirais.
“As alterações identificadas surgem como alvos terapêuticos cuja modulação poderá reduzir a morbidade e a mortalidade na sepse”, afirma Rossi.
E eles não são os únicos a pensar assim.
Na Universidade de Utah, nos Estados Unidos, o grupo chefiado pelo cardiologista Dean Li, do qual participa o médico brasileiro Fernando Augusto Bozza, do Instituto de Pesquisa Clínica Evandro Chagas, no Rio de Janeiro, tentou controlar as reações inflamatórias decorrentes da sepse ou da gripe aviária de maneira inusitada.
Os pesquisadores deram aos camundongos um composto que impedia que os comunicadores químicos que alimentam a inflamação deixassem a corrente sanguínea e chegassem aos tecidos.
Assim, conseguiram reduzir o nível de dano no organismo dos roe­dores, segundo artigo publicado em 17 de março na Science Translational Medicine.
“Ao bloquear os efeitos nocivos da inflamação no hospedeiro e estabilizar os vasos sanguíneos, identificamos uma estratégia totalmente diferente para tratar essas infecções”, disse Li.
“Em essência, mostramos que, em vez de atacar o patógeno, podemos mirar o hospedeiro para ajudá-lo a lutar contra a infecção.”
O controle adequado da sepse, porém, deve exigir mais de uma estratégia de ação.
Em um trabalho recente feito em parceria com pesquisadores da Universidade de Glasgow, na Escócia, o farmacologista José Carlos Alves Filho, da equipe de Cunha, administrou a camundongos com sepse uma proteína naturalmente produzida pelas células do sistema de defesa que atua como um comunicador químico de ação anti-inflamatória: a interleucina 33 ou IL-33.
Além de reduzir a inflamação no organismo sem a eliminar no foco original de infecção, essa proteína estimulou a migração de um tipo específico de células de defesa – os neutrófilos – que eliminam as bactérias de modo eficiente.
Os resultados dessa terapia experimental foram claros.
Apenas 20% dos roedores tratados com IL-33 morreram em consequência da sepse, enquanto a taxa de mortalidade no grupo que recebeu um composto inócuo foi de 80%.
No artigo em que apresentam esses dados na Nature Medicine de 16 de maio, os pesquisadores sugerem que o efeito que a IL-33 produziu nos camundongos também deve ser observado nos seres humanos, uma vez que os neutrófilos são menos ativos nas pessoas que desenvolvem quadros mais graves de sepse.
Menos de um mês antes, outro integrante da equipe de Cunha e de Rossi, o farmacologista Fernando Spiller, havia demonstrado que o uso de sulfeto de hidrogênio – ou ácido sulfídrico (H2S), o gás responsável pelo mau cheiro dos ovos podres – induz a migração de neutrófilos e de outro grupo de células de defesa, os leucócitos, para a área inicial de infecção (ver Pesquisa FAPESP nº 146).
Esse reforço celular eliminou as bactérias e reduziu para 13% a mortalidade entre os camundongos que receberam o composto, ante quase 80% entre os que não foram tratados, segundo artigo publicado no American Journal of Respiratory and Critical Care Medicine.
Apesar de animadores, esses avanços representam apenas o passo inicial de um longo percurso para melhorar o controle da sepse, problema de saúde pública especialmente grave nos países em desenvolvimento, onde os recursos são mais escassos.
Um levantamento feito anos atrás pelo Instituto Latino-americano para Estudos da Sepse revelou que, dos R$ 41 bilhões gastos em 2003 com terapia intensiva pelo sistema de saúde brasileiro, mais de R$ 17 bilhões foram destinados a tratamento de 400 mil pacientes com sepse, dos quais 227 mil morreram.
> Artigos científicos
1.
Shock.
v.
27 (1), p.
1-18.
jan.
2007.
2.
Disruption of sarcolemmal dystrophin and beta-dystroglycan may be a potential mechanism for myocardial dysfunction in severe sepsis.
Laboratory Investigation.
v.
90, p.
531-42.
fev.
2010.
Os Projetos
1.
2.
3.
Modalidade
1 e 2.
Projeto Temático
3.
Auxílio Regular a Projeto de Pesquisa
Sergio Henrique Ferreira – usp/rp
3.
Marcos Antonio Rossi – usp/rp
Investimento
R$ 2.303.227,35
R$ 153.565,78
R$ 310.920,30
Memória >
O botânico que fazia livros na Corte
Há 210 anos frei Mariano Veloso produziu obras voltadas para os problemas do Brasil Colônia
Neldson Marcolin
Por três anos, entre 1799 e 1801, um editor brasileiro em Lisboa reuniu em torno de si e de uma tipografia um grupo de brasileiros e portugueses ilustrados empenhados em produzir textos técnicos europeus.
Em sua maioria, tratava-se de questões ligadas à agricultura e aos modos de produção mais eficientes do que os adotados por fazendeiros e criadores em Portugal e no Brasil.
A fama de frei Veloso, porém, vem de antes.
Seu nome de batismo era José Veloso Xavier, nascido na antiga São José d’El Rei, hoje Tiradentes (MG).
Pouco se conhece sobre a formação do religioso.
Sabe-se que aos 19 anos entrou para o convento de São Boaventura de Macacu e depois de cinco anos seguiu para o de Santo Antônio, no Rio.
Tornou-se professor de geometria e de história natural, mas seu principal interesse sempre foi a botânica.
Em 1783 o frade estava oficialmente ligado ao governo português como um dos encarregados de realizar viagens filosóficas, como se dizia na época, de reconhecimento da Colônia e coleta de espécimes da fauna e flora que enviavam à Corte.
A admiração por Veloso levou o vice-rei Luís de Vasconcelos e Sousa – que tinha especial apreço pelas ciências naturais – a determinar que ele realizasse excursões por toda a província do Rio para recolher e examinar as plantas fluminenses.
Por oito anos (1783-1790) Veloso coletou milhares de exemplares que viriam a dar forma à sua obra maior, a Flora fluminense.
Vários companheiros de congregação o ajudavam nas definições das plantas e desenharam o que havia sido colhido.
A Flora fluminense reuniu 1.626 espécies distribuídas em 396 gêneros.
Sua publicação, em 10 volumes, percorreu um longo périplo e ocorreu por completo apenas em 1881, 70 anos depois da morte de Veloso.
Veloso, em virtude de sua formação em grande parte autodidata, não tinha um relacionamento confortável com a Academia Real das Ciências de Portugal.
A comunidade de naturalistas portugueses nunca o reconheceu como um dos seus, de acordo com os historiadores Maria de Fátima Nunes e João Carlos Brigola, da Universidade de Évora, de Portugal, em ensaio biográfico que integra o livro A Casa Literária do Arco do Cego (Imprensa Nacional/Casa da Moeda/Biblioteca Nacional, Lisboa, 1999).
Veloso foi para Lisboa em 1790 e seis anos depois publicou o periódico agrário Paladio Portuguez e Clarim de Palas, que tratava das novidades e aprimoramento na agricultura, manufaturas e comércio.
Em 1799 foi nomeado para a Arco do Cego e mesmo após a tipografia ter sido absorvida pela Imprensa Régia, em 1801, continuou trabalhando na área.
“Veloso publicava os livros sempre preocupado com os problemas da Colônia”, diz a historiadora Márcia Ferraz, do Centro Simão Mathias de Estudos de História da Ciência, da Pontifícia Universidade Católica de São Paulo (PUC-SP).
“A série O fazendeiro do Brasil, por exemplo, eram 11 volumes que tratavam desde a fabricação de açúcar ao cultivo de café, cacau, das plantas tintureiras e ensinava a preparar derivados de leite.”
Nos três anos da Arco do Cego foram escritos ou traduzidos 83 livros, muitos deles publicados em parceria com outras tipografias.
Os temas abrangiam agricultura, história natural, medicina e saúde pública, náutica, ciências exatas, poesia e história.
As gravuras e desenhos técnicos eram abundantes, com objetivo claramente didático.
Com a invasão francesa em 1808, Veloso voltou ao Rio onde morreu em 1811, aos 69 anos.
Seu trabalho como editor e botânico foi reconhecido na maior parte do tempo.
Faltou ver sua obra maior publicada em vida.
Entrevista >
Fabrício Marques
Para o pioneiro na pesquisa em fisiologia renal no Brasil, Gerhard Malnic, de 76 anos, um dos prazeres de fazer ciên­cia sempre foi a possibilidade de usar as próprias mãos, fosse para manipular e dosar o fluido extraído de minúsculos túbulos dos rins de animais de laboratório e de seres humanos, fosse para inventar equipamentos, micropipetas e porta-eletrodos talhados para técnicas que ele próprio desenvolveu e hoje são citadas em livros de referência.
``Hoje isso é mais raro, mas no meu tempo era uma coisa fantástica'', diz o pesquisador, com sua voz pausada e um remoto sotaque germânico.
Professor titular do Departamento de Fisiologia e Biofísica do Instituto de Ciências Biomédicas (ICB) da Universidade de São Paulo (USP), Malnic nasceu em Milão, filho de austríacos, e mudou-se para o Brasil aos 4 anos de idade, naturalizando-se brasileiro aos 23.
Radicado em São Paulo, onde o pai, químico, trabalharia como representante de uma indústria alemã de corantes e, mais tarde, no império dos Matarazzo, Malnic estudou no Colégio Visconde de Porto Seguro.
Interessou-se pela fisiologia no segundo ano de faculdade e, sob influência do professor Alberto Carvalho da Silva, especializou-se em fisiologia renal, área ainda pouco explorada no Brasil.
Fez seu pós-doutoramento na Tulane University, Nova Orleans, entre 1961 e 1962, e na Cornell University Medical College, Nova York, entre 1962 e 1964 no laboratório do austríaco Gerhard Giebisch, com quem colabora até hoje.
De volta à USP, implantou o laboratório de micropunção e microperfusão renal, um método de colheita de fluido dos túbulos renais (onde a água, sais minerais e vitaminas são devolvidos para o sangue, restando a urina) por meio de micropipetas, estudou os mecanismos de transporte de potássio dentro do rim, além do papel do sódio, fatores hormonais, alterações do equilíbrio ácido-base e drogas nefrotóxicas na reabsorção de bicarbonato.
Tem mais de 120 trabalhos publicados em revistas internacionais, além de um livro sobre fisiologia renal.
Já formou oito mestres e duas dezenas de doutores e se tornou uma das principais referências em seu campo no Brasil.
Paralelamente ao trabalho de bancada, presidiu entidades científicas, como a Sociedade Brasileira de Biofísica (1983-1985), a Sociedade Brasileira de Fisiologia (1985-1988), a Federação de Sociedades de Biologia Experimental (Fesbe) e o Instituto de Estudos Avançados (IEA) da USP.
Aposentado, já testemunhou a saída de cena de alguns de seus discípulos, mas segue na ativa em seu laboratório no ICB.
Por isso acho que não vão pôr a gente para fora, apesar da idade'', diz, em tom de brincadeira.
``No momento, só tenho uma doutoranda, mas estou tentando obter mais alguns.
Os jovens preferem ficar com os mais jovens também'', diz.
Casado com a professora e tradutora Margot Petry Malnic, pai de duas filhas, a bioquímica Betina e a cantora e arranjadora Beatriz, avô de três netas, Gerhard Malnic deu a Pesquisa FAPESP a entrevista a seguir:
O senhor nasceu na Itália, mas tem nacionalidade austríaca.
Como chegou ao Brasil?
-- Nasci na Itália, mas por acaso.
Meu pai nasceu em 1901 na Áustria, onde hoje é a Croácia.
O nome Malnic é eslavo.
A família do pai dele era eslovena e minha mãe era austríaca, então tenho mais ascendentes alemães do que eslovenos.
Meu pai estudou química, se formou em 1925, aproximadamente, num momento muito difícil para a Áustria, que praticamente acabou depois da Primeira Guerra Mundial.
Ele trabalhou em vários países depois da guerra, entre os quais a Alemanha, a Polônia e a Itália, onde eu nasci e minha irmã também.
Mas vim para cá com 4 anos.
Por que sua família veio para o Brasil?
-- Meu pai era químico, colorista.
Trabalhou na Itália, numa indústria de tecidos.
Os corantes eram, na Alemanha, a base da química.
Ele foi contratado por uma indústria química alemã para vir para o Brasil.
Uma das razões era que ele tinha experiência em países latinos.
Então ele veio para cá com uma representação no Brasil desta firma.
Viemos primeiro para o Rio e ele logo percebeu que o interessante mesmo, em termos de indústria, era São Paulo.
Mudamos para cá e eu fui para o Colégio Visconde de Porto Seguro desde os 6, 7 anos.
Que era uma escola da colônia alemã...
-- É da colônia alemã, desde o século XIX.
Essa escola foi por assim dizer nacionalizada por causa da guerra.
Aprendi alemão lá também.
Em casa aprendi um pouco de latim e grego, porque meu pai achava importante.
Ele aprendeu isso no Gymnasium, em Viena, então achava que eu também tinha que aprender um pouco.
Mas o fato é que, chegando aqui, trabalhou durante algum tempo nessa firma, que depois foi confiscada pelo governo, quando o Brasil entrou na Segunda Guerra.
E aí ele trabalhou na Matarazzo, no bairro do Belenzinho, em uma fábrica de tecidos.
No Visconde de Porto Seguro, tive facilidade para estudar.
A guerra não me atingiu.
Meu pai era uma pessoa com meios.
Se recolocou, depois comprou uma fazenda no norte do Paraná e trabalhou em outras firmas químicas.
Eu sempre gostei de química porque meu pai fazia química e até montou um pequeno laboratório em casa.
Mas ele me sugeriu: ``Olha, aqui no Brasil a melhor faculdade é a de medicina, é melhor você fazer medicina''.
Segui o conselho dele.
Como era a Faculdade de Medicina da USP quando o senhor se formou?
-- Isso foi a partir de 1952.
Não era muito diferente de hoje.
Entrei em primeiro lugar no vestibular.
Comecei a trabalhar na fisiologia no 2o ano de medicina.
Meu professor era o Alberto Carvalho da Silva, que viria a ser diretor da FAPESP.
Era uma pessoa fantástica, que criou um bom laboratório.
Ele trabalhava com vitaminas, mas achava que eu não devia trabalhar com elas porque já havia quem fizesse isso.
Uma coisa que ele queria fazer era trabalhar com a parte renal das vitaminas, como elas eram eliminadas.
E sentamos juntos na bancada para ler um livro do fisiologista americano Homer Smith, isso em 1954.
Comecei a estudar em cães excreção renal de vitamina B1 ou tiamina.
A novidade era tanto estudar excreção renal de vitaminas como trabalhar com cães não anestesiados.
Porque existia a ideia de que o animal anestesiado, principalmente no caso da vitamina, poderia sofrer mudanças de funcionamento, então trabalhamos com cão não anestesiado.
Com muito cuidado, sem produzir dor... Era meio complicado porque a gente tinha que canular o ureter, facilitar a colheita de urina, obter amostras de sangue e, além disso, as dosagens das vitaminas eram muito complicadas.
Este trabalho deu o meu primeiro paper, com o doutor Alberto, no American Journal of Physiology, uma das mais prestigiosas revistas de fisiologia.
Havia grupos trabalhando nisso no Brasil?
-- Tinha gente na área clínica, o doutor José de Barros Magaldi, por exemplo.
Ele era o chefe da clínica da Faculdade de Medicina; e tinha o grupo da Escola Paulista de Medicina, também na parte clínica.
Mas em fisiologia tinha algumas pessoas que trabalhavam como clínicos e tinham laboratório, como o Marcelo Marcondes, que está aposentado agora, o Antonino Rocha, que veio um pouco mais tarde, foi aluno do Marcondes e nós trabalhamos juntos depois.
O Antonino Rocha foi assassinado por um bandido que queria roubar o carro dele, já naquele tempo tinha dessas coisas.
A sua escolha pela fisiologia renal foi influenciada pelo professor Alberto, é isso?
Fomos juntos a um congresso internacional de fisiologia em Buenos Aires e conversamos com o professor Robert Franklin Pitts, que era um dos maiores fisiologistas renais da época.
E ele disse: ``Eu tenho dois jovens que estão começando a trabalhar comigo e eles falam alemão e estão começando com uma área nova da fisiologia'', que era a micropunção.
Naquele livro do Homer Smith descrevia-se todo o primeiro tempo da micropunção, como puncionar túbulos renais e obter amostras.
É uma técnica que começou no fim dos anos 1920, começo dos 30.
Usavam essa técnica para obter detalhes do funcionamento dos túbulos renais e também dos glomérulos renais [unidades funcionais dos rins através das quais se produz a filtração do sangue].
O professor Pitts disse: ``Venha para o meu laboratório, que fica em Nova York, na Cornell University Medical College''.
Então consegui uma bolsa da Fundação Rockefeller.
Naquele tempo não existia FAPESP, mas a Rockefeller ajudava muito o Brasil.
Tinha ajudado o próprio doutor Alberto.
Fui para Nova York, mas primeiro tive que fazer um ano de estudos básicos porque não havia pós-gra­­duação aqui.
Sempre fui uma pessoa que aceitava boas sugestões.
E achei uma ideia interessante.
Passei um ano na Tulane University, em Nova Orleans, estudando inglês, matemática, bioquímica, segui alguns cursos de fisiologia e aproveitei muitos deles.
Meu inglês era bom, em casa eu tinha tido aula particular.
E mesmo matemática eu sabia um pouco mais que os outros.
Então fiz um curso de físico-química, que os outros não faziam, o que para mim foi excelente porque desde cedo me interessei por mecanismos de transporte iônico, para o que matemática era importante.
Consegui então completar esse curso, que muito me ajudou no restante do estágio.
Em que época?
-- Isto foi em 1961, 1962.
Neste curso havia vários brasileiros e outros latino-americanos.
Era um programa da Fundação Rockefeller para estimular a ciência latino-americana.
Fiquei um ano em Nova Orleans, de lá fui para o laboratório do Robert Franklin Pitts e encontrei os dois jovens pesquisadores, que eram austríacos, por coincidência.
E eles não sabiam que eu era de origem austríaca: ``É um brasileiro, vamos ver como funciona''.
Quem eram eles?
Ele trabalhou durante algum tempo com uma pesquisadora, a Phillis Bott, que havia trabalhado com o A.N.
Richards, pioneiro que desenvolveu a micropunção.
Ela trabalhava no Women's Medical College de Philadelphia, uma faculdade de medicina para mulheres de Filadélfia, naquele tempo existia isso, faculdade só para mulheres.
Naquele tempo não era tão complicado em termos de equipamento, mas ganhei um microscópio da Faculdade de Medicina, que o doutor Alberto conseguiu para mim, e uma série de outras coisas, micromanipuladoras, dosador de cloreto, da Phillis Bott.
Hoje, quando a gente chega num laboratório desses nos Estados Unidos, tem uns 10 ou 15 outros pós-docs trabalhando e você vê o seu chefe de longe.
Naquele tempo era o Giebisch, eu e uma técnica, então a gente trabalhava junto mesmo, o que era muito positivo para começar uma coisa nova.
Desenvolvemos um método para fazer microdosagem de sódio e potássio e, daí, estudamos os mecanismos de excreção de potássio.
E conseguimos observar como se dava a excreção de potássio nos vários segmentos tubulares, nos túbulos renais.
Antigamente só se obtinha a comparação entre sangue e urina, e nós pudemos puncionar os vários túbulos, túbulo proximal, túbulo distal, separadamente.
Conseguimos descobrir como o potássio era excretado.
E o que fizemos naquela época era uma coisa pioneira, que os livros de fisiologia todos trazem, até hoje.
Como foi o retorno ao Brasil?
-- Vim montar um laboratório.
E apesar das dificuldades iniciais, consegui fazer bastante coisa.
A primeira coisa era estudar o jeito de manejar cloreto, que também só fiz porque tinha um aparelho adequado.
Como eu não sabia muito bem o que ia fazer, resolvi: ``Bom, vamos fazer alguma coisa que dê para fazer com o que tenho: vou fazer micropunção, e alguma coisa com cloreto''.
Tirava uma amostra de fluido tubular e fazia uma dosagem bastante complicada.
Pouca gente fazia porque era difícil demais de fazer.
Mas eu era cabeça-dura.
E com isso consegui impulsionar o trabalho na Faculdade de Medicina, consegui publicar na Nature, sobre o efeito do diurético furosemide no transporte de cloretos.
Eu tinha conseguido o material, inventei o projeto.
Depois reconstruí aqui esse equipamento de microdosagem de sódio e potássio, o que foi possível porque a gente na Fisiologia tinha uma espécie de laboratório mecânico, tinha gente capaz de construir coisas.
Veja esse aparelho [mostra um equipamento antigo exposto em seu laboratório].
Tem uma pequena chama no meio e nessa pequena chama a gente colocava uma alça de platina, em cima da alça de platina punha uma gota de água e, dentro da água, a solução obtida do túbulo renal.
Para fazer isso aqui tive ajuda do meu primeiro aluno de doutorado, o professor Francisco Lacaz Vieira.
Ele entendia muito de eletricidade e eletrônica, me fez o equipamento, ajudou a construir a parte eletrônica, que eram duas válvulas, uma de cada lado, uma para potássio e outra para sódio, e tinha que ter 2 mil volts -- alta voltagem, naquele tempo.
Fizemos isso e deu certo.
Minha sorte era ter o Francisco Lacaz, que se aposentou uns dois anos atrás.
O tio dele, o Joaquim Lacaz de Moraes, tinha montado um belíssimo laboratório.
Ele era neurofisiologista, mas era também desses de construir coisas, de eletricidade, a família dos Lacaz era muito boa de eletrônica.
Então ele montou um laboratório em cima da atual biblioteca da faculdade.
Nesse laboratório a gente tinha um espaço enorme que não era de todo usado.
Então começou a trabalhar comigo, o que foi ótimo, porque ele me ajudou muito.
É uma pessoa com muita habilidade, muito inteligente, foi professor titular aqui durante muito tempo...
Sugeri a ele medir pH nos túbulos renais, e ele conseguiu para isso fazer um microeletrodo de antimônio.
Produzimos coisas muito interessantes.
Era preciso fabricar o próprio equi­pamento.
-- É, para produzir alguma coisa.
E produzimos então o trabalho dos mecanismos de secreção de hidrogênio, a produção de ácido por parte do rim.
Tinha mais de 300 citações.
Era um estudo da secreção de íon hidrogênio nos túbulos renais.
Era uma coisa que estava sendo feita, outros fizeram mas não usaram esse mesmo método, esse mesmo microeletrodo.
Solomon.
Havia um descompasso entre o que o senhor podia fazer lá e aqui?
-- Havia, mas naquele tempo a gente conseguia fazer muita coisa no laboratório.
Nós tivemos durante muito tempo uma boa oficina mecânica no departamento.
Infelizmente nosso mecânico morreu alguns anos atrás e não foi reposto, porque hoje em dia a fisiologia mudou, não é mais uma fisiologia que a gente tem que pôr a mão.
É a fisiologia mais da biologia molecular, que tem equipamentos que se usam sempre, como o espectrofotômetro, centrífugas, coisa assim, que você compra mas não faz.
E gostei muito de usar as próprias mãos, o que, para a micropunção renal, era fundamental, porque a gente produzia os porta-eletrodos, as micropipetas, tinha que fazer isso.
Você ficava lá todo dia construindo uma coisa ou outra.
Hoje isso é mais raro.
Que outros trabalhos o senhor destaca?
-- Temos os trabalhos de potássio e de sódio.
O professor Giebisch, nos Estados Unidos, contribuiu muito, mas eu colaborei com ele -- até hoje a gente colabora e fizemos muita coisa juntos, principalmente de sódio e potássio.
Aqui trabalhei, além de sódio e potássio, com hidrogênio.
Estudamos a acidificação dos túbulos renais.
E isso foi feito, também, primeiro com microeletrodos, que são microinstrumentos feitos em microforja, onde a gente produz uma ponta preenchida por antimônio -- o antimônio é um metal sensível a pH.
Depois passamos do antimônio para uma resina de troca iônica, que é uma espécie de solução meio oleosa que a gente coloca dentro do eletrodo e que contém uma substância também sensível a pH.
Eu estive no fim do ano passado na Yale University, em New Haven, com uma aluna minha, a Lucilia Lessa, de Fortaleza, e o Giebisch sempre dizia: ``Você é o único no mundo que sabe fazer essa técnica, de microperfusão, de dosagem de potássio com microeletrodos''.
Tenho cerca de 130 trabalhos, mais ou menos.
Para os Estados Unidos não é tanto, mas para nós aqui... E é bom porque nossos métodos são muito complicados, difíceis de fazer e, nisso, levam muito tempo.
Quantos pesquisadores o senhor formou?
-- Formei 20 e tantos doutores...
Alguns deles continuaram com essa técnica.
Uma pessoa que contribuiu muito foi a professora Margarida de Mello Aires, que é minha vizinha de sala.
Ela fez o doutorado comigo logo quando eu voltei, uns dois ou três anos depois, veio trabalhar comigo.
E ela trabalha com micropunção, microperfusão desde aquela época, desde 1966 mais ou menos.
E tem muitos outros.
Tenho um trabalho feito com o Marcelo Marcondes e outro com o Antonino Rocha, com o pessoal da Faculdade de Medicina.
Estudamos por micropunção os túbulos renais de ratos com doença renal.
Ultimamente tenho trabalhado muito com pH, equilíbrio ácido-base, de que jeito o rim acidifica a urina, que é uma das funções muito importantes do rim.
E, em outra área, fui para os Estados Unidos para trabalhar com camundongos transgênicos.
Hoje isto se faz muito, é uma técnica muito poderosa.
Aqui é mais difícil, temos dificuldade de produzir estes camundongos aqui.
Mas fui ao laboratório da Yale University, tanto em 2004 quanto no fim do ano passado, e trabalhamos com camundongos que têm falta de um transportador de íons, no caso, de potássio.
Uma outra aluna, a Nancy Rebouças, desenvolveu a parte de biologia molecular, após um estágio na Yale, em parte por minha sugestão.
Ela agora é uma das pessoas importantes em São Paulo que trabalham com biologia molecular.
Outro colega, o Antônio Carlos Cassola, trabalha com uma técnica eletrofisiológica, patch clamp, que utiliza microeletrodos também, que aprendeu no mesmo laboratório com o Giebisch e um aluno deste, Y.
Wang.
O nosso grupo todo se desenvolveu daquele começo.
Colabora conosco, ainda, a Adriana Girardi, ex-aluna de doutorado da Nancy Rebouças, atualmente no Instituto do Coração, que trabalha com coração e rim, outra excelente bióloga molecular.
-- Nos mudamos para cá em 1972.
Ganhamos um espaço que não era maior do que na Faculdade de Medicina.
Agora estamos reduzindo um pouco porque, como estou aposentado, a Margarida também, a gente tem que se limitar um pouco, enquanto não põem a gente para fora [risos].
Qual é o foco de seu projeto temático?
-- O nome do temático é ``Estudo molecular e funcional de transportadores de íons em membranas''.
Investigamos como os túbulos renais transportam sódio, potássio e hidrogênio.
É uma continuidade do que a gente tem feito nestes anos.
A Nancy trabalha com a parte de biologia molecular do projeto.
A própria Adriana, do InCor, e a gente de nosso laboratório, tem colaborado nesta área, tem publicado trabalhos de biologia molecular, principalmente com ajuda delas e de uma pós-doc do nosso laboratório, ex-aluna da Nancy e minha, Luciene Carraro-Lacroix, e que agora está fazendo um pós-doc no Canadá.
Em que estágio está a pesquisa em fisiologia no Brasil?
Como evoluímos?
-- No início do século passado, a fisiologia dependeu muito de esforços individuais.
No Rio, o professor Carlos Chagas começou trabalhando no Instituto Oswaldo Cruz.
Naquele tempo, no Rio principalmente, a fisiologia das faculdades era mais uma fisiologia de ensino e a fisiologia científica era mais feita nos institutos, como Manguinhos.
Aqui foi um pouco diferente.
A Faculdade de Medicina foi criada em 1913, ela começou logo, pelo menos em parte, com pesquisa e ensino ao mesmo tempo.
A parte de pesquisa em fisiologia estava, no Rio, no Instituto de Biofísica do Carlos Chagas, ainda hoje o centro de pesquisa mais importante do Rio, e aqui, em boa parte, estava na Faculdade de Medicina.
Temos várias pessoas trabalhando nas diferentes áreas de fisiologia, a cardiovascular, a neurofisiologia e atualmente a endocrinologia.
A neurofisiologia é bastante boa, principalmente depois da passagem do professor Miguel Covian, vindo de Buenos Aires, em Ribeirão Preto.
E aqui ti­vemos o professor César Timo-Iaria, que foi aluno de Covian, ambos já falecidos.
O professor César veio de Ribeirão para cá e criou um grupo de neurofisiologia que ainda é muito bom.
Portanto, a fisiologia cresceu progressivamente em várias áreas.
Mas há no Brasil outros bons grupos de fisiologia, destacando-se Ribeirão Preto, Belo Horizonte e Porto Alegre.
No Espírito Santo há um bom grupo de cárdio também.
Realmente houve um crescimento bastante razoável.
A pós-graduação ajudou muito, atraiu muita gente para a área e me­­lhorou muito sua qualidade.
O professor Covian veio da Argentina, nos anos 1950, país que era referência em fisiologia.
Ainda é?
-- Naquela época, eles já tinham um Prêmio Nobel, o Bernardo Houssay.
Havia grupos de bioquímica muito bons, como o do também vencedor do Nobel, Luis Leloir.
Hoje é difícil dizer se está melhor ou pior...
Acho que está mais para pior do que para melhor.
A fisiologia aqui, com a pós-graduação, cresceu muito.
Como presidente da Fesbe, o senhor foi um dos líderes da mobilização para remover entraves para os experimentos científicos com animais.
Foi algo importante?
-- Sim, porque a gente tem oponentes poderosos, sociedades de proteção aos animais, e eles nos causaram muitas dificuldades.
Inclusive em alguns locais houve invasão de biotérios para libertar animais.
Finalmente saiu a nova lei, de Sérgio Arouca, que morreu antes de ver a lei aprovada, e foi muito positiva.
Agora a gente precisa que, em cada unidade, cada faculdade, se crie um conselho de ética para experimentos em animais.
Isso já havia para humanos.
Agora estão começando as comissões para animais, o que é muito positivo porque é claro que te­mos que tratar muito bem nossos animais, dar anestesias adequadas, não fazê-los sofrer.
Isso é muito importante.
Mas não se pode deixar de usar animais em ciência, isso também é fundamental.
De certo modo, havia um lado positivo nessa pressão, no sentido de estimular a busca de métodos alternativos, não?
-- Sim, de dar um tratamento adequado para os animais.
A gente usava muito cachorro.
Pegavam os cachorros na rua e depois eram utilizados em pesquisa.
Os americanos usam mais cachorros especialmente criados para isso.
Mas aqui é difícil fazer.
A minha tese de doutorado sobre a vitamina B1 foi feita com cão.
Hoje usamos mais rato, porque rato é criado especialmente para isso, então é mais agradável e bem mais controlável.
Não parece tanto com animal de estimação como cachorro e gato.
Eu lembro que o doutor Alberto usava gato para experimentos de nutrição porque os gatos são muito bons para estudos em que a gente precisa de animais muito homogêneos.
O tamanho do crânio do gato varia muito pouco, ao contrário do cão.
O crânio dos gatos é muito semelhante entre indivíduos, e isso facilita muito os estudos de neurofisiologia.
Agora o gato é um animal muito protegido pela sociedade, então hoje praticamente não se usa mais.
E dá para fazer muita coisa em rato também.
Camundongo se usa muito hoje para biologia molecular.
A gente fez micropunção com camundongo.
É mais difícil, é um animalzinho muito menor, mas é o mais apropriado para produzir animais transgênicos.
Num artigo que escreveu para um livro sobre o ensino superior, o senhor fala sobre mérito dentro da universidade, como a universidade deveria trocar quem não está funcionando e dar acesso aos pesquisadores mais jovens.
A questão o preocupa?
-- Até certo ponto.
Agora, com a pós-graduação, isso diminuiu, porque a pessoa para entrar na Faculdade de Medicina ou no ICB ou num lugar bom tem que passar pela pós-graduação, e isso em geral melhora muito o nível das pessoas.
Mas nem todo mundo que passou pela pós-graduação continua muito produtivo.
Tem gente cuja produtividade cai depois de alguns anos.
E a questão é o que fazer com essas pessoas.
Elas muitas vezes vão mais para a administração ou o ensino.
Ou, agora, vão também para a indústria.
Isto dá muita briga.
Teoricamente, realmente, o que deveria acontecer é que a progressão na carreira deveria depender do mérito.
Isso talvez tenha melhorado um pouco, porque antigamente o pessoal dava mais aula do que fazia pesquisa.
É importante que se saiba dar aula bem.
Mas o ideal é tanto dar aula como fazer pesquisa, as duas coisas.
Em outros países não há a estabilidade na carreira de docente pesquisador que temos aqui.
-- Talvez fosse uma boa ideia.
Mas não acredito que aconteça, porque a força das entidades de defesa de classe é muito grande.
Essas entidades são poderosas.
A gente deveria ter mais vantagens, inclusive pecuniárias, para quem produz mais, como acontece nos Estados Unidos.
Lá a situação é diferente porque as entidades como a FAPESP é que pagam uma boa parte do salário.
Então o indivíduo que não produz perde boa parte do salário e tende a mudar de vida, ganhar dinheiro de outra forma.
Aqui não tem isso.
É muito confortável.
Até a sua morte você ganha o mesmo salário, que não é dos piores.
Mas o sistema de financiamento tem evoluído...
-- Temos, em quase todos os estados, fundações de amparo à pesquisa, as FAPs.
A existência dessas FAPs permitiu que os docentes que produzem ganhem mais dinheiro para pesquisa.
Vão produzir mais ainda, por causa desse apoio financeiro das FAPs e mesmo do CNPq [Conselho Nacional de Desenvolvimento Científico e Tecnológico].
Isso é uma coisa positiva e acaba escolhendo os melhores para continuar nas universidades.
Inclusive os docentes com maior produção podem receber bolsas do CNPq, que já são um estímulo adicional.
A Faculdade de Medicina tem uma coisa boa.
Eles ajudam no salário a partir da Fundação Faculdade de Medicina.
O pessoal apoiado acaba ganhando mais -- e com justiça.
É uma maneira de apoiar os que trabalham mais no laboratório, porque na Medicina isso é essencial.
O pessoal que trabalha em tempo integral lá não ficaria em tempo integral com o salário-base que a gente ganha.
Voltando à sua carreira, quais são seus planos para o futuro?
-- Continuo fazendo pesquisa enquanto for possível.
Eu tenho 76 anos agora e não sei até quando será possível continuar.
Estou bem de saúde.
Já sofri uma cirurgia de coluna, a coluna estava apertando os nervos das pernas e consegui recuperar bem isso.
Claro que reduzi um pouco.
A gente sempre acaba com menos elã do que tinha na juventude, isso é forçoso.
Mesmo assim estou conseguindo fazer bastante coisa.
O contato com os jovens, por exemplo, é uma coisa que estimula.
No momento, só tenho uma doutoranda e um aluno de iniciação.
Os jovens preferem ficar com os mais jovens também.
Mas a gente sempre acaba conseguindo mais alguém.
Do ponto de vista da pesquisa, continuo trabalhando em excreção de potássio e com camundongos transgênicos.
Inclusive, nosso setor de importação do ICB tem conseguido importar estes camundongos.
Mas tenho colaborado também com colegas em estudos sobre acidificação tubular do ponto de vista de mecanismo de transporte de íons H.
